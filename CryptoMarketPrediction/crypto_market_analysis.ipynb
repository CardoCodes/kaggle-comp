{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Crypto Market Analysis\n",
        "\n",
        "## Pearson Correlation Coefficient (PCC) for Model Evaluation\n",
        "\n",
        "The Pearson correlation coefficient (ρ) measures the linear correlation between two variables, in our case between the actual labels (y) and predicted values (ŷ) on the private test set. It ranges from -1 to +1, where:\n",
        "\n",
        "- +1 indicates perfect positive linear correlation\n",
        "- 0 indicates no linear correlation  \n",
        "- -1 indicates perfect negative linear correlation\n",
        "\n",
        "# The formula for PCC is:\n",
        "# \n",
        "# $\\rho = \\frac{Cov(y,\\hat{y})}{\\sigma_y \\cdot \\sigma_{\\hat{y}}}$\n",
        "\n",
        "Where:\n",
        "- Cov(y,ŷ) is the covariance between actual and predicted values\n",
        "- σy is the standard deviation of actual values\n",
        "- σŷ is the standard deviation of predicted values\n",
        "\n",
        "For this competition, the evaluation metric is the Pearson correlation between our predictions and the true labels on the private test set. A higher positive correlation indicates better predictive performance, as our predictions more closely track the actual market movements.\n",
        "\n",
        "Key implications:\n",
        "- We want our predictions to move in the same direction as actual values\n",
        "- The magnitude of movements matters less than getting the direction right\n",
        "- A correlation of 0.7+ would indicate strong predictive performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Ready to analyze DRW Crypto Market Prediction data...\n"
          ]
        }
      ],
      "source": [
        "# DRW - Crypto Market Prediction Analysis\n",
        "# Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "import joblib\n",
        "import os\n",
        "import zipfile\n",
        "import warnings\n",
        "from sklearn.base import clone\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options for better output\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(\"Ready to analyze DRW Crypto Market Prediction data...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Data:\n",
            "Shape: (525887, 896)\n",
            "\n",
            "First few rows (showing first 7 columns):\n",
            "                     bid_qty  ask_qty  buy_qty  sell_qty   volume        X1  \\\n",
            "timestamp                                                                     \n",
            "2023-03-01 00:00:00   15.283    8.425  176.405    44.984  221.389  0.121263   \n",
            "2023-03-01 00:01:00   38.590    2.336  525.846   321.950  847.796  0.302841   \n",
            "2023-03-01 00:02:00    0.442   60.250  159.227   136.369  295.596  0.167462   \n",
            "2023-03-01 00:03:00    4.865   21.016  335.742   124.963  460.705  0.072944   \n",
            "2023-03-01 00:04:00   27.158    3.451   98.411    44.407  142.818  0.173820   \n",
            "\n",
            "                           X2  \n",
            "timestamp                      \n",
            "2023-03-01 00:00:00 -0.417690  \n",
            "2023-03-01 00:01:00 -0.049576  \n",
            "2023-03-01 00:02:00 -0.291212  \n",
            "2023-03-01 00:03:00 -0.436590  \n",
            "2023-03-01 00:04:00 -0.213489  \n",
            "\n",
            "Test Data:\n",
            "Shape: (538150, 896)\n",
            "\n",
            "First few rows (showing first 7 columns):\n",
            "    bid_qty  ask_qty  buy_qty  sell_qty   volume        X1        X2\n",
            "ID                                                                  \n",
            "1     0.114   12.121   10.587    10.971   21.558 -0.732818  0.512331\n",
            "2     2.426    2.962  136.241    12.304  148.545 -0.337995 -0.412176\n",
            "3     1.085    2.343   23.390    57.171   80.561  0.111249  0.458221\n",
            "4    14.793    1.117  116.518    13.082  129.600 -0.149399 -0.640638\n",
            "5     0.033   14.178   43.800    49.836   93.636 -0.694662  0.611254\n",
            "\n",
            "Sample Submission:\n",
            "Shape: (538150, 2)\n",
            "\n",
            "First few rows:\n",
            "   ID  prediction\n",
            "0   1   -0.280233\n",
            "1   2    1.371969\n",
            "2   3   -2.045252\n",
            "3   4   -1.447555\n",
            "4   5   -1.303901\n"
          ]
        }
      ],
      "source": [
        "# Load and examine the crypto market data\n",
        "# First, let's identify the main data files (both CSV and Parquet)\n",
        "data_dir = \"./data/\"\n",
        "all_files = os.listdir(data_dir)\n",
        "csv_files = [f for f in all_files if f.endswith('.csv')]\n",
        "parquet_files = [f for f in all_files if f.endswith('.parquet')]\n",
        "\n",
        "# Load the main dataset(s)\n",
        "train_data = None\n",
        "test_data = None\n",
        "sample_submission = None\n",
        "\n",
        "# Function to load data based on file extension\n",
        "def load_data_file(filepath):\n",
        "    if filepath.endswith('.csv'):\n",
        "        return pd.read_csv(filepath)\n",
        "    elif filepath.endswith('.parquet'):\n",
        "        return pd.read_parquet(filepath)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {filepath}\")\n",
        "\n",
        "# Try to identify train, test, and submission files\n",
        "all_data_files = csv_files + parquet_files\n",
        "for file in all_data_files:\n",
        "    filepath = os.path.join(data_dir, file)\n",
        "    \n",
        "    if 'train' in file.lower():\n",
        "        train_data = load_data_file(filepath)\n",
        "        \n",
        "    elif 'test' in file.lower() and 'submission' not in file.lower():\n",
        "        test_data = load_data_file(filepath)\n",
        "        \n",
        "    elif 'submission' in file.lower():\n",
        "        sample_submission = load_data_file(filepath)\n",
        "\n",
        "\n",
        "# Display basic information about the datasets\n",
        "if train_data is not None:\n",
        "    print(\"\\nTraining Data:\")\n",
        "    print(f\"Shape: {train_data.shape}\")\n",
        "    print(\"\\nFirst few rows (showing first 7 columns):\")\n",
        "    print(train_data.iloc[:5, :7])\n",
        "\n",
        "if test_data is not None:\n",
        "    print(\"\\nTest Data:\")\n",
        "    print(f\"Shape: {test_data.shape}\")\n",
        "    print(\"\\nFirst few rows (showing first 7 columns):\")\n",
        "    print(test_data.iloc[:5, :7])\n",
        "\n",
        "if sample_submission is not None:\n",
        "    print(\"\\nSample Submission:\")\n",
        "    print(f\"Shape: {sample_submission.shape}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(sample_submission.head())\n",
        "\n",
        "if train_data is None and test_data is None:\n",
        "    print(\"No train or test data loaded. Please check if the data files exist.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reduce Memory Usage\n",
        "\n",
        "Next we need to reduce the amounr of RAM that the pandas dataframe is using. When loading data, panda often assignes default values line int64 or float64. We can reduce the memory usage by converting these to smaller datatypes. We simply need to iterate over the columns and check the min and max values of each column. If the min and max values are within the range of the smaller datatypes, we can convert the column to that datatype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reduce_mem_usage(dataframe, dataset):\n",
        "    print('Reducing memory usage for:', dataset)\n",
        "    initial_mem_usage = dataframe.memory_usage().sum() / 1024**2\n",
        "    \n",
        "    # Select only numeric columns\n",
        "    numeric_cols = dataframe.select_dtypes(include=[np.number]).columns\n",
        "    \n",
        "    for col in numeric_cols:\n",
        "        c_min = dataframe[col].min()\n",
        "        c_max = dataframe[col].max()\n",
        "        \n",
        "        if np.issubdtype(dataframe[col].dtype, np.integer):\n",
        "            types = [np.int8, np.int16, np.int32, np.int64]\n",
        "            for t in types:\n",
        "                if c_min >= np.iinfo(t).min and c_max <= np.iinfo(t).max:\n",
        "                    dataframe[col] = dataframe[col].astype(t)\n",
        "                    break\n",
        "        elif np.issubdtype(dataframe[col].dtype, np.floating):\n",
        "            types = [np.float16, np.float32, np.float64]\n",
        "            for t in types:\n",
        "                if c_min >= np.finfo(t).min and c_max <= np.finfo(t).max:\n",
        "                    dataframe[col] = dataframe[col].astype(t)\n",
        "                    break\n",
        "    \n",
        "    final_mem_usage = dataframe.memory_usage().sum() / 1024**2\n",
        "    print('--- Memory usage before: {:.2f} MB'.format(initial_mem_usage))\n",
        "    print('--- Memory usage after: {:.2f} MB'.format(final_mem_usage))\n",
        "    print('--- Decreased memory usage by {:.1f}%\\n'.format(100 * (initial_mem_usage - final_mem_usage) / initial_mem_usage))\n",
        "    \n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Seperating the data into training and testing sets\n",
        "\n",
        "The foundation for building our models is to split the data into training and testing sets. We will use the training set to train our models and the testing set to evaluate their performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reducing memory usage for: train_data\n",
            "--- Memory usage before: 3598.94 MB\n",
            "--- Memory usage after: 965.94 MB\n",
            "--- Decreased memory usage by 73.2%\n",
            "\n",
            "Reducing memory usage for: test_data\n",
            "--- Memory usage before: 3678.76 MB\n",
            "--- Memory usage after: 984.36 MB\n",
            "--- Decreased memory usage by 73.2%\n",
            "\n",
            "Data successfully split into training and testing sets.\n",
            "X (training features) shape: (525887, 895)\n",
            "y (training target) shape: (525887,)\n",
            "X_test (test features) shape: (538150, 895)\n"
          ]
        }
      ],
      "source": [
        "target_col = 'label'\n",
        "\n",
        "#reduce mem usage \n",
        "train_data = reduce_mem_usage(train_data, 'train_data')\n",
        "test_data = reduce_mem_usage(test_data, 'test_data')\n",
        "\n",
        "#split data into training and testing sets\n",
        "if target_col in train_data.columns:\n",
        "    X = train_data.drop(target_col, axis=1)\n",
        "    y = train_data[target_col]\n",
        "\n",
        "    if target_col in test_data.columns:\n",
        "        X_test = test_data.drop(target_col, axis=1)\n",
        "    else:\n",
        "        X_test = test_data.copy() # Use .copy() to avoid SettingWithCopyWarning later\n",
        "\n",
        "    print(\"Data successfully split into training and testing sets.\")\n",
        "    print(f\"X (training features) shape: {X.shape}\")\n",
        "    print(f\"y (training target) shape: {y.shape}\")\n",
        "    print(f\"X_test (test features) shape: {X_test.shape}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: Target column '{target_col}' not found in the training data.\")\n",
        "    print(\"Please update the 'target_col' variable with the correct column name.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Black Box Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature selection applied.\n",
            "New shape of X (training features): (5259, 25)\n",
            "New shape of X_test (test features): (5382, 25)\n"
          ]
        }
      ],
      "source": [
        "# Define the list of features identified as most important through prior analysis.\n",
        "# This combines domain-specific features and data-driven anonymous features.\n",
        "\n",
        "features = [\n",
        "    # Top features identified from the referenced Kaggle notebook\n",
        "    \"X863\", \"X856\", \"X344\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
        "    \"X415\", \"X345\", \"X137\", \"X855\", \"X174\", \"X302\", \"X178\", \"X532\", \"X168\", \"X612\",\n",
        "    \n",
        "    # Core market microstructure features\n",
        "    \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\"\n",
        "]\n",
        "\n",
        "X = X[features]\n",
        "X_test = X_test[features]\n",
        "\n",
        "print(\"Feature selection applied.\")\n",
        "print(f\"New shape of X (training features): {X.shape}\")\n",
        "print(f\"New shape of X_test (test features): {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Fold 1 ---\n",
            "Fold 1 Score: nan\n",
            "--- Fold 2 ---\n",
            "Fold 2 Score: nan\n",
            "--- Fold 3 ---\n",
            "Fold 3 Score: nan\n",
            "--- Fold 4 ---\n",
            "Fold 4 Score: nan\n",
            "--- Fold 5 ---\n",
            "Fold 5 Score: nan\n",
            "\n",
            "--- XGBoost Training Summary ---\n",
            "Fold Scores: [np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan), np.float64(nan)]\n",
            "Overall OOF Score (Pearson): -0.034295\n",
            "Test predictions shape: (5382,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Trainer:\n",
        "    \"\"\"\n",
        "    A wrapper class to simplify cross-validated model training, prediction,\n",
        "    and evaluation. It handles out-of-fold predictions and aggregates scores.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, cv, metric, task=\"regression\", metric_precision=6):\n",
        "        self.model = model\n",
        "        self.cv = cv\n",
        "        self.metric = metric\n",
        "        self.task = task\n",
        "        self.metric_precision = metric_precision\n",
        "        self.models_ = []\n",
        "        self.fold_scores = []\n",
        "        self.oof_preds = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fits the model using the provided cross-validation strategy.\n",
        "        It stores the trained model for each fold and computes out-of-fold predictions.\n",
        "        \"\"\"\n",
        "        self.models_ = []\n",
        "        self.oof_preds = np.zeros(len(X))\n",
        "        \n",
        "        # Check if input data is a pandas DataFrame or Series\n",
        "        is_pandas = hasattr(X, 'iloc')\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y)):\n",
        "            print(f\"--- Fold {fold+1} ---\")\n",
        "\n",
        "            if is_pandas:\n",
        "                X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "                X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
        "            else:  # Assume numpy array\n",
        "                X_train, y_train = X[train_idx], y[train_idx]\n",
        "                X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "            fold_model = clone(self.model)\n",
        "            fold_model.fit(X_train, y_train)\n",
        "            self.models_.append(fold_model)\n",
        "\n",
        "            val_preds = fold_model.predict(X_val)\n",
        "            self.oof_preds[val_idx] = val_preds\n",
        "\n",
        "            score, _ = self.metric(y_val, val_preds)\n",
        "            self.fold_scores.append(round(score, self.metric_precision))\n",
        "            print(f\"Fold {fold+1} Score: {self.fold_scores[-1]}\")\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Generates test set predictions by averaging the predictions \n",
        "        from all models trained during cross-validation.\n",
        "        \"\"\"\n",
        "        if not self.models_:\n",
        "            raise RuntimeError(\"The trainer has not been fitted yet. Call .fit() before .predict().\")\n",
        "\n",
        "        test_predictions = np.zeros(len(X_test))\n",
        "        for model in self.models_:\n",
        "            test_predictions += model.predict(X_test)\n",
        "        \n",
        "        return test_predictions / len(self.models_)\n",
        "\n",
        "# Define XGBoost model parameters from your notebook\n",
        "xgb_params = {\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"device\": \"gpu\",\n",
        "    \"colsample_bylevel\": 0.4778,\n",
        "    \"colsample_bynode\": 0.3628,\n",
        "    \"colsample_bytree\": 0.7107,\n",
        "    \"gamma\": 1.7095,\n",
        "    \"learning_rate\": 0.02213,\n",
        "    \"max_depth\": 20,\n",
        "    \"max_leaves\": 12,\n",
        "    \"min_child_weight\": 16,\n",
        "    \"n_estimators\": 1667,\n",
        "    \"subsample\": 0.06567,\n",
        "    \"reg_alpha\": 39.3524,\n",
        "    \"reg_lambda\": 75.4484,\n",
        "    \"verbosity\": 0,\n",
        "    \"random_state\": 42,\n",
        "    \"n_jobs\": -1\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to store results for different models\n",
        "fold_scores = {}\n",
        "overall_scores = {}\n",
        "oof_preds = {}\n",
        "test_preds = {}\n",
        "\n",
        "# Instantiate the trainer with the XGBoost regressor and parameters\n",
        "xgb_trainer = Trainer(\n",
        "    model=XGBRegressor(**xgb_params),\n",
        "    cv=KFold(n_splits=5, shuffle=False),\n",
        "    metric=pearsonr,\n",
        "    task=\"regression\",\n",
        "    metric_precision=6\n",
        ")\n",
        "\n",
        "# Assuming X, y, and X_test are defined and available in your environment\n",
        "# Fit the model and generate out-of-fold predictions\n",
        "xgb_trainer.fit(X, y)\n",
        "\n",
        "# Store the results\n",
        "fold_scores[\"XGBoost\"] = xgb_trainer.fold_scores\n",
        "overall_scores[\"XGBoost\"] = [pearsonr(xgb_trainer.oof_preds, y)[0]]\n",
        "oof_preds[\"XGBoost\"] = xgb_trainer.oof_preds\n",
        "test_preds[\"XGBoost\"] = xgb_trainer.predict(X_test)\n",
        "\n",
        "# Print a summary of the training results\n",
        "print(\"\\n--- XGBoost Training Summary ---\")\n",
        "print(f\"Fold Scores: {fold_scores['XGBoost']}\")\n",
        "print(f\"Overall OOF Score (Pearson): {overall_scores['XGBoost'][0]:.6f}\")\n",
        "print(f\"Test predictions shape: {test_preds['XGBoost'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Ridge' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      6\u001b[39m joblib.dump(X_test, \u001b[33m\"\u001b[39m\u001b[33mtest_preds.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m ridge_params = {\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33malpha\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.001\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m42\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpositive\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m ridge_trainer = Trainer(\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m         \u001b[43mRidge\u001b[49m(**ridge_params),\n\u001b[32m     18\u001b[39m         cv=KFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m     19\u001b[39m         metric=pearsonr,\n\u001b[32m     20\u001b[39m         task=\u001b[33m\"\u001b[39m\u001b[33mregression\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m         verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     22\u001b[39m     )\n\u001b[32m     24\u001b[39m ridge_trainer.fit(X, y)\n\u001b[32m     26\u001b[39m fold_scores[\u001b[33m\"\u001b[39m\u001b[33mRidge (ensemble)\u001b[39m\u001b[33m\"\u001b[39m] = ridge_trainer.fold_scores\n",
            "\u001b[31mNameError\u001b[39m: name 'Ridge' is not defined"
          ]
        }
      ],
      "source": [
        "# add an ensemble model with ridge regression\n",
        "X = pd.DataFrame(oof_preds)\n",
        "X_test = pd.DataFrame(test_preds)\n",
        "\n",
        "joblib.dump(X, \"oof_preds.pkl\")\n",
        "joblib.dump(X_test, \"test_preds.pkl\")\n",
        "\n",
        "ridge_params = {\n",
        "    'alpha': 0.001,\n",
        "    'random_state': 42,\n",
        "    'tol': 1e-3,\n",
        "    'fit_intercept': True,\n",
        "    'positive': True\n",
        "}\n",
        "\n",
        "ridge_trainer = Trainer(\n",
        "        Ridge(**ridge_params),\n",
        "        cv=KFold(n_splits=5, shuffle=False),\n",
        "        metric=pearsonr,\n",
        "        task=\"regression\",\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "ridge_trainer.fit(X, y)\n",
        "\n",
        "fold_scores[\"Ridge (ensemble)\"] = ridge_trainer.fold_scores\n",
        "overall_scores[\"Ridge (ensemble)\"] = [pearsonr(ridge_trainer.oof_preds, y)]\n",
        "ridge_test_preds = ridge_trainer.predict(X_test)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
