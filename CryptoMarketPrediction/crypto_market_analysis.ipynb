{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pearson Correlation Coefficient (PCC) for Model Evaluation\n",
        "\n",
        "The Pearson correlation coefficient (ρ) measures the linear correlation between two variables, in our case between the actual labels (y) and predicted values (ŷ) on the private test set. It ranges from -1 to +1, where:\n",
        "\n",
        "- +1 indicates perfect positive linear correlation\n",
        "- 0 indicates no linear correlation  \n",
        "- -1 indicates perfect negative linear correlation\n",
        "\n",
        "# The formula for PCC is:\n",
        "# \n",
        "# $\\rho = \\frac{Cov(y,\\hat{y})}{\\sigma_y \\cdot \\sigma_{\\hat{y}}}$\n",
        "\n",
        "Where:\n",
        "- Cov(y,ŷ) is the covariance between actual and predicted values\n",
        "- σy is the standard deviation of actual values\n",
        "- σŷ is the standard deviation of predicted values\n",
        "\n",
        "For this competition, the evaluation metric is the Pearson correlation between our predictions and the true labels on the private test set. A higher positive correlation indicates better predictive performance, as our predictions more closely track the actual market movements.\n",
        "\n",
        "Key implications:\n",
        "- We want our predictions to move in the same direction as actual values\n",
        "- The magnitude of movements matters less than getting the direction right\n",
        "- A correlation of 0.7+ would indicate strong predictive performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Ready to analyze DRW Crypto Market Prediction data...\n"
          ]
        }
      ],
      "source": [
        "# DRW - Crypto Market Prediction Analysis\n",
        "# Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options for better output\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(\"Ready to analyze DRW Crypto Market Prediction data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Data:\n",
            "Shape: (525887, 896)\n",
            "\n",
            "First few rows (showing first 7 columns):\n",
            "                     bid_qty  ask_qty  buy_qty  sell_qty   volume        X1  \\\n",
            "timestamp                                                                     \n",
            "2023-03-01 00:00:00   15.283    8.425  176.405    44.984  221.389  0.121263   \n",
            "2023-03-01 00:01:00   38.590    2.336  525.846   321.950  847.796  0.302841   \n",
            "2023-03-01 00:02:00    0.442   60.250  159.227   136.369  295.596  0.167462   \n",
            "2023-03-01 00:03:00    4.865   21.016  335.742   124.963  460.705  0.072944   \n",
            "2023-03-01 00:04:00   27.158    3.451   98.411    44.407  142.818  0.173820   \n",
            "\n",
            "                           X2  \n",
            "timestamp                      \n",
            "2023-03-01 00:00:00 -0.417690  \n",
            "2023-03-01 00:01:00 -0.049576  \n",
            "2023-03-01 00:02:00 -0.291212  \n",
            "2023-03-01 00:03:00 -0.436590  \n",
            "2023-03-01 00:04:00 -0.213489  \n",
            "\n",
            "Test Data:\n",
            "Shape: (538150, 896)\n",
            "\n",
            "First few rows (showing first 7 columns):\n",
            "    bid_qty  ask_qty  buy_qty  sell_qty   volume        X1        X2\n",
            "ID                                                                  \n",
            "1     0.114   12.121   10.587    10.971   21.558 -0.732818  0.512331\n",
            "2     2.426    2.962  136.241    12.304  148.545 -0.337995 -0.412176\n",
            "3     1.085    2.343   23.390    57.171   80.561  0.111249  0.458221\n",
            "4    14.793    1.117  116.518    13.082  129.600 -0.149399 -0.640638\n",
            "5     0.033   14.178   43.800    49.836   93.636 -0.694662  0.611254\n",
            "\n",
            "Sample Submission:\n",
            "Shape: (538150, 2)\n",
            "\n",
            "First few rows:\n",
            "   ID  prediction\n",
            "0   1   -0.280233\n",
            "1   2    1.371969\n",
            "2   3   -2.045252\n",
            "3   4   -1.447555\n",
            "4   5   -1.303901\n"
          ]
        }
      ],
      "source": [
        "# Load and examine the crypto market data\n",
        "# First, let's identify the main data files (both CSV and Parquet)\n",
        "data_dir = \"./data/\"\n",
        "all_files = os.listdir(data_dir)\n",
        "csv_files = [f for f in all_files if f.endswith('.csv')]\n",
        "parquet_files = [f for f in all_files if f.endswith('.parquet')]\n",
        "\n",
        "# Load the main dataset(s)\n",
        "train_data = None\n",
        "test_data = None\n",
        "sample_submission = None\n",
        "\n",
        "# Function to load data based on file extension\n",
        "def load_data_file(filepath):\n",
        "    if filepath.endswith('.csv'):\n",
        "        return pd.read_csv(filepath)\n",
        "    elif filepath.endswith('.parquet'):\n",
        "        return pd.read_parquet(filepath)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {filepath}\")\n",
        "\n",
        "# Try to identify train, test, and submission files\n",
        "all_data_files = csv_files + parquet_files\n",
        "for file in all_data_files:\n",
        "    filepath = os.path.join(data_dir, file)\n",
        "    \n",
        "    if 'train' in file.lower():\n",
        "        train_data = load_data_file(filepath)\n",
        "        \n",
        "    elif 'test' in file.lower() and 'submission' not in file.lower():\n",
        "        test_data = load_data_file(filepath)\n",
        "        \n",
        "    elif 'submission' in file.lower():\n",
        "        sample_submission = load_data_file(filepath)\n",
        "\n",
        "\n",
        "# Display basic information about the datasets\n",
        "if train_data is not None:\n",
        "    print(\"\\nTraining Data:\")\n",
        "    print(f\"Shape: {train_data.shape}\")\n",
        "    print(\"\\nFirst few rows (showing first 7 columns):\")\n",
        "    print(train_data.iloc[:5, :7])\n",
        "\n",
        "if test_data is not None:\n",
        "    print(\"\\nTest Data:\")\n",
        "    print(f\"Shape: {test_data.shape}\")\n",
        "    print(\"\\nFirst few rows (showing first 7 columns):\")\n",
        "    print(test_data.iloc[:5, :7])\n",
        "\n",
        "if sample_submission is not None:\n",
        "    print(\"\\nSample Submission:\")\n",
        "    print(f\"Shape: {sample_submission.shape}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(sample_submission.head())\n",
        "\n",
        "if train_data is None and test_data is None:\n",
        "    print(\"No train or test data loaded. Please check if the data files exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data successfully split into training and testing sets.\n",
            "X (training features) shape: (525887, 895)\n",
            "y (training target) shape: (525887,)\n",
            "X_test (test features) shape: (538150, 895)\n"
          ]
        }
      ],
      "source": [
        "target_col = 'label'\n",
        "\n",
        "if target_col in train_data.columns:\n",
        "    X = train_data.drop(target_col, axis=1)\n",
        "    y = train_data[target_col]\n",
        "\n",
        "    if target_col in test_data.columns:\n",
        "        X_test = test_data.drop(target_col, axis=1)\n",
        "    else:\n",
        "        X_test = test_data.copy() # Use .copy() to avoid SettingWithCopyWarning later\n",
        "\n",
        "    print(\"Data successfully split into training and testing sets.\")\n",
        "    print(f\"X (training features) shape: {X.shape}\")\n",
        "    print(f\"y (training target) shape: {y.shape}\")\n",
        "    print(f\"X_test (test features) shape: {X_test.shape}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: Target column '{target_col}' not found in the training data.\")\n",
        "    print(\"Please update the 'target_col' variable with the correct column name.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature selection applied.\n",
            "New shape of X (training features): (525887, 25)\n",
            "New shape of X_test (test features): (538150, 25)\n"
          ]
        }
      ],
      "source": [
        "# Define the list of features identified as most important through prior analysis.\n",
        "# This combines domain-specific features and data-driven anonymous features.\n",
        "\n",
        "features = [\n",
        "    # Top features identified from the referenced Kaggle notebook\n",
        "    \"X863\", \"X856\", \"X344\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
        "    \"X415\", \"X345\", \"X137\", \"X855\", \"X174\", \"X302\", \"X178\", \"X532\", \"X168\", \"X612\",\n",
        "    \n",
        "    # Core market microstructure features\n",
        "    \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\"\n",
        "]\n",
        "\n",
        "X = X[features]\n",
        "X_test = X_test[features]\n",
        "\n",
        "print(\"Feature selection applied.\")\n",
        "print(f\"New shape of X (training features): {X.shape}\")\n",
        "print(f\"New shape of X_test (test features): {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Fold 1 ---\n",
            "Fold 1 Score: 0.1843\n",
            "--- Fold 2 ---\n",
            "Fold 2 Score: 0.130448\n",
            "--- Fold 3 ---\n",
            "Fold 3 Score: 0.084011\n",
            "--- Fold 4 ---\n",
            "Fold 4 Score: 0.163249\n",
            "--- Fold 5 ---\n",
            "Fold 5 Score: 0.128591\n",
            "\n",
            "--- XGBoost Training Summary ---\n",
            "Fold Scores: [np.float64(0.1843), np.float64(0.130448), np.float64(0.084011), np.float64(0.163249), np.float64(0.128591)]\n",
            "Overall OOF Score (Pearson): 0.134930\n",
            "Test predictions shape: (538150,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.base import clone\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"\n",
        "    A wrapper class to simplify cross-validated model training, prediction,\n",
        "    and evaluation. It handles out-of-fold predictions and aggregates scores.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, cv, metric, task=\"regression\", metric_precision=6):\n",
        "        self.model = model\n",
        "        self.cv = cv\n",
        "        self.metric = metric\n",
        "        self.task = task\n",
        "        self.metric_precision = metric_precision\n",
        "        self.models_ = []\n",
        "        self.fold_scores = []\n",
        "        self.oof_preds = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fits the model using the provided cross-validation strategy.\n",
        "        It stores the trained model for each fold and computes out-of-fold predictions.\n",
        "        \"\"\"\n",
        "        self.models_ = []\n",
        "        self.oof_preds = np.zeros(len(X))\n",
        "        \n",
        "        # Check if input data is a pandas DataFrame or Series\n",
        "        is_pandas = hasattr(X, 'iloc')\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y)):\n",
        "            print(f\"--- Fold {fold+1} ---\")\n",
        "\n",
        "            if is_pandas:\n",
        "                X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "                X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
        "            else:  # Assume numpy array\n",
        "                X_train, y_train = X[train_idx], y[train_idx]\n",
        "                X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "            fold_model = clone(self.model)\n",
        "            fold_model.fit(X_train, y_train)\n",
        "            self.models_.append(fold_model)\n",
        "\n",
        "            val_preds = fold_model.predict(X_val)\n",
        "            self.oof_preds[val_idx] = val_preds\n",
        "\n",
        "            score, _ = self.metric(y_val, val_preds)\n",
        "            self.fold_scores.append(round(score, self.metric_precision))\n",
        "            print(f\"Fold {fold+1} Score: {self.fold_scores[-1]}\")\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Generates test set predictions by averaging the predictions \n",
        "        from all models trained during cross-validation.\n",
        "        \"\"\"\n",
        "        if not self.models_:\n",
        "            raise RuntimeError(\"The trainer has not been fitted yet. Call .fit() before .predict().\")\n",
        "\n",
        "        test_predictions = np.zeros(len(X_test))\n",
        "        for model in self.models_:\n",
        "            test_predictions += model.predict(X_test)\n",
        "        \n",
        "        return test_predictions / len(self.models_)\n",
        "\n",
        "# Define XGBoost model parameters from your notebook\n",
        "xgb_params = {\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"device\": \"gpu\",\n",
        "    \"colsample_bylevel\": 0.4778,\n",
        "    \"colsample_bynode\": 0.3628,\n",
        "    \"colsample_bytree\": 0.7107,\n",
        "    \"gamma\": 1.7095,\n",
        "    \"learning_rate\": 0.02213,\n",
        "    \"max_depth\": 20,\n",
        "    \"max_leaves\": 12,\n",
        "    \"min_child_weight\": 16,\n",
        "    \"n_estimators\": 1667,\n",
        "    \"subsample\": 0.06567,\n",
        "    \"reg_alpha\": 39.3524,\n",
        "    \"reg_lambda\": 75.4484,\n",
        "    \"verbosity\": 0,\n",
        "    \"random_state\": 42,\n",
        "    \"n_jobs\": -1\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to store results for different models\n",
        "fold_scores = {}\n",
        "overall_scores = {}\n",
        "oof_preds = {}\n",
        "test_preds = {}\n",
        "\n",
        "# Instantiate the trainer with the XGBoost regressor and parameters\n",
        "xgb_trainer = Trainer(\n",
        "    model=XGBRegressor(**xgb_params),\n",
        "    cv=KFold(n_splits=5, shuffle=False),\n",
        "    metric=pearsonr,\n",
        "    task=\"regression\",\n",
        "    metric_precision=6\n",
        ")\n",
        "\n",
        "# Assuming X, y, and X_test are defined and available in your environment\n",
        "# Fit the model and generate out-of-fold predictions\n",
        "xgb_trainer.fit(X, y)\n",
        "\n",
        "# Store the results\n",
        "fold_scores[\"XGBoost\"] = xgb_trainer.fold_scores\n",
        "overall_scores[\"XGBoost\"] = [pearsonr(xgb_trainer.oof_preds, y)[0]]\n",
        "oof_preds[\"XGBoost\"] = xgb_trainer.oof_preds\n",
        "test_preds[\"XGBoost\"] = xgb_trainer.predict(X_test)\n",
        "\n",
        "# Print a summary of the training results\n",
        "print(\"\\n--- XGBoost Training Summary ---\")\n",
        "print(f\"Fold Scores: {fold_scores['XGBoost']}\")\n",
        "print(f\"Overall OOF Score (Pearson): {overall_scores['XGBoost'][0]:.6f}\")\n",
        "print(f\"Test predictions shape: {test_preds['XGBoost'].shape}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
