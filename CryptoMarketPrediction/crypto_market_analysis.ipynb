{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pearson Correlation Coefficient (PCC) for Model Evaluation\n",
        "\n",
        "The Pearson correlation coefficient (ρ) measures the linear correlation between two variables, in our case between the actual labels (y) and predicted values (ŷ) on the private test set. It ranges from -1 to +1, where:\n",
        "\n",
        "- +1 indicates perfect positive linear correlation\n",
        "- 0 indicates no linear correlation  \n",
        "- -1 indicates perfect negative linear correlation\n",
        "\n",
        "# The formula for PCC is:\n",
        "# \n",
        "# $\\rho = \\frac{Cov(y,\\hat{y})}{\\sigma_y \\cdot \\sigma_{\\hat{y}}}$\n",
        "\n",
        "Where:\n",
        "- Cov(y,ŷ) is the covariance between actual and predicted values\n",
        "- σy is the standard deviation of actual values\n",
        "- σŷ is the standard deviation of predicted values\n",
        "\n",
        "For this competition, the evaluation metric is the Pearson correlation between our predictions and the true labels on the private test set. A higher positive correlation indicates better predictive performance, as our predictions more closely track the actual market movements.\n",
        "\n",
        "Key implications:\n",
        "- We want our predictions to move in the same direction as actual values\n",
        "- The magnitude of movements matters less than getting the direction right\n",
        "- A correlation of 0.7+ would indicate strong predictive performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'__reduce_cython__'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mticker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaxNLocator, FormatStrFormatter, PercentFormatter\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\xgboost\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Booster,\n\u001b[32m     10\u001b[39m     DataIter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     build_info,\n\u001b[32m     16\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\xgboost\\tracker.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\xgboost\\core.py:39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_data_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m     TransformedDf,\n\u001b[32m     41\u001b[39m     array_interface,\n\u001b[32m     42\u001b[39m     cuda_array_interface,\n\u001b[32m     43\u001b[39m     from_array_interface,\n\u001b[32m     44\u001b[39m     make_array_interface,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     47\u001b[39m     _T,\n\u001b[32m     48\u001b[39m     ArrayLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     c_bst_ulong,\n\u001b[32m     67\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PANDAS_INSTALLED, DataFrame, import_polars, py_str\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\xgboost\\_data_utils.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CNumericPtr, DataType, NumpyOrCupy\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_cupy\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_ArrayLikeArg\u001b[39;00m(Protocol):\n\u001b[32m     15\u001b[39m     \u001b[38;5;129m@property\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\xgboost\\compat.py:53\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RegressorMixin \u001b[38;5;28;01mas\u001b[39;00m XGBRegressorBase\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold \u001b[38;5;28;01mas\u001b[39;00m XGBStratifiedKFold\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold \u001b[38;5;28;01mas\u001b[39;00m XGBStratifiedKFold\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_classification_threshold\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     FixedThresholdClassifier,\n\u001b[32m     10\u001b[39m     TunedThresholdClassifierCV,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_plot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ValidationCurveDisplay\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, ParameterGrid, ParameterSampler, RandomizedSearchCV\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_classification_threshold.py:17\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     BaseEstimator,\n\u001b[32m     11\u001b[39m     ClassifierMixin,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     clone,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     check_scoring,\n\u001b[32m     19\u001b[39m     get_scorer_names,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_scorer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     _CurveScorer,\n\u001b[32m     23\u001b[39m     _threshold_scores_to_class_labels,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, get_tags\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Score functions, performance metrics, pairwise metrics and distance computations.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_classification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     accuracy_score,\n\u001b[32m      9\u001b[39m     balanced_accuracy_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     zero_one_loss,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dist_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistanceMetric\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\cluster\\__init__.py:28\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bicluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m consensus_score\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_supervised\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     adjusted_mutual_info_score,\n\u001b[32m     14\u001b[39m     adjusted_rand_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     v_measure_score,\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unsupervised\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     calinski_harabasz_score,\n\u001b[32m     30\u001b[39m     davies_bouldin_score,\n\u001b[32m     31\u001b[39m     silhouette_samples,\n\u001b[32m     32\u001b[39m     silhouette_score,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m __all__ = [\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madjusted_mutual_info_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madjusted_rand_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mv_measure_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:20\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _atol_for_type\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     Interval,\n\u001b[32m     17\u001b[39m     StrOptions,\n\u001b[32m     18\u001b[39m     validate_params,\n\u001b[32m     19\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VALID_METRICS, pairwise_distances, pairwise_distances_chunked\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_number_of_labels\u001b[39m(n_labels, n_samples):\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m        Number of samples.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples, check_non_negative\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pairwise_distances_reduction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArgKmin\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pairwise_fast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Utility Functions\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\__init__.py:94\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m \u001b[38;5;66;03m#    (see :class:`MiddleTermComputer{32,64}`).\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dispatcher\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     ArgKmin,\n\u001b[32m     96\u001b[39m     ArgKminClassMode,\n\u001b[32m     97\u001b[39m     BaseDistancesReductionDispatcher,\n\u001b[32m     98\u001b[39m     RadiusNeighbors,\n\u001b[32m     99\u001b[39m     RadiusNeighborsClassMode,\n\u001b[32m    100\u001b[39m     sqeuclidean_row_norms,\n\u001b[32m    101\u001b[39m )\n\u001b[32m    103\u001b[39m __all__ = [\n\u001b[32m    104\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mArgKmin\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    105\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mArgKminClassMode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msqeuclidean_row_norms\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m ]\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# ruff: noqa: E501\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:16\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dist_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     BOOL_METRICS,\n\u001b[32m     13\u001b[39m     METRIC_MAPPING64,\n\u001b[32m     14\u001b[39m     DistanceMetric,\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_argkmin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     ArgKmin32,\n\u001b[32m     18\u001b[39m     ArgKmin64,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_argkmin_classmode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     ArgKminClassMode32,\n\u001b[32m     22\u001b[39m     ArgKminClassMode64,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n",
            "\u001b[36mFile \u001b[39m\u001b[32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:1\u001b[39m, in \u001b[36minit sklearn.metrics._pairwise_distances_reduction._argkmin\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: '__reduce_cython__'"
          ]
        }
      ],
      "source": [
        "# DRW - Crypto Market Prediction Analysis\n",
        "# Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options for better output\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(\"Ready to analyze DRW Crypto Market Prediction data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Data:\n",
            "Shape: (525887, 896)\n",
            "\n",
            "First few rows (showing first 7 columns):\n",
            "                     bid_qty  ask_qty  buy_qty  sell_qty   volume        X1  \\\n",
            "timestamp                                                                     \n",
            "2023-03-01 00:00:00   15.283    8.425  176.405    44.984  221.389  0.121263   \n",
            "2023-03-01 00:01:00   38.590    2.336  525.846   321.950  847.796  0.302841   \n",
            "2023-03-01 00:02:00    0.442   60.250  159.227   136.369  295.596  0.167462   \n",
            "2023-03-01 00:03:00    4.865   21.016  335.742   124.963  460.705  0.072944   \n",
            "2023-03-01 00:04:00   27.158    3.451   98.411    44.407  142.818  0.173820   \n",
            "\n",
            "                           X2  \n",
            "timestamp                      \n",
            "2023-03-01 00:00:00 -0.417690  \n",
            "2023-03-01 00:01:00 -0.049576  \n",
            "2023-03-01 00:02:00 -0.291212  \n",
            "2023-03-01 00:03:00 -0.436590  \n",
            "2023-03-01 00:04:00 -0.213489  \n",
            "\n",
            "Test Data:\n",
            "Shape: (538150, 896)\n",
            "\n",
            "First few rows (showing first 7 columns):\n",
            "    bid_qty  ask_qty  buy_qty  sell_qty   volume        X1        X2\n",
            "ID                                                                  \n",
            "1     0.114   12.121   10.587    10.971   21.558 -0.732818  0.512331\n",
            "2     2.426    2.962  136.241    12.304  148.545 -0.337995 -0.412176\n",
            "3     1.085    2.343   23.390    57.171   80.561  0.111249  0.458221\n",
            "4    14.793    1.117  116.518    13.082  129.600 -0.149399 -0.640638\n",
            "5     0.033   14.178   43.800    49.836   93.636 -0.694662  0.611254\n",
            "\n",
            "Sample Submission:\n",
            "Shape: (538150, 2)\n",
            "\n",
            "First few rows:\n",
            "   ID  prediction\n",
            "0   1   -0.280233\n",
            "1   2    1.371969\n",
            "2   3   -2.045252\n",
            "3   4   -1.447555\n",
            "4   5   -1.303901\n"
          ]
        }
      ],
      "source": [
        "# Load and examine the crypto market data\n",
        "# First, let's identify the main data files (both CSV and Parquet)\n",
        "data_dir = \"./data/\"\n",
        "all_files = os.listdir(data_dir)\n",
        "csv_files = [f for f in all_files if f.endswith('.csv')]\n",
        "parquet_files = [f for f in all_files if f.endswith('.parquet')]\n",
        "\n",
        "# Load the main dataset(s)\n",
        "train_data = None\n",
        "test_data = None\n",
        "sample_submission = None\n",
        "\n",
        "# Function to load data based on file extension\n",
        "def load_data_file(filepath):\n",
        "    if filepath.endswith('.csv'):\n",
        "        return pd.read_csv(filepath)\n",
        "    elif filepath.endswith('.parquet'):\n",
        "        return pd.read_parquet(filepath)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {filepath}\")\n",
        "\n",
        "# Try to identify train, test, and submission files\n",
        "all_data_files = csv_files + parquet_files\n",
        "for file in all_data_files:\n",
        "    filepath = os.path.join(data_dir, file)\n",
        "    \n",
        "    if 'train' in file.lower():\n",
        "        train_data = load_data_file(filepath)\n",
        "        \n",
        "    elif 'test' in file.lower() and 'submission' not in file.lower():\n",
        "        test_data = load_data_file(filepath)\n",
        "        \n",
        "    elif 'submission' in file.lower():\n",
        "        sample_submission = load_data_file(filepath)\n",
        "\n",
        "\n",
        "# Display basic information about the datasets\n",
        "if train_data is not None:\n",
        "    print(\"\\nTraining Data:\")\n",
        "    print(f\"Shape: {train_data.shape}\")\n",
        "    print(\"\\nFirst few rows (showing first 7 columns):\")\n",
        "    print(train_data.iloc[:5, :7])\n",
        "\n",
        "if test_data is not None:\n",
        "    print(\"\\nTest Data:\")\n",
        "    print(f\"Shape: {test_data.shape}\")\n",
        "    print(\"\\nFirst few rows (showing first 7 columns):\")\n",
        "    print(test_data.iloc[:5, :7])\n",
        "\n",
        "if sample_submission is not None:\n",
        "    print(\"\\nSample Submission:\")\n",
        "    print(f\"Shape: {sample_submission.shape}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(sample_submission.head())\n",
        "\n",
        "if train_data is None and test_data is None:\n",
        "    print(\"No train or test data loaded. Please check if the data files exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data successfully split into training and testing sets.\n",
            "X (training features) shape: (525887, 895)\n",
            "y (training target) shape: (525887,)\n",
            "X_test (test features) shape: (538150, 895)\n"
          ]
        }
      ],
      "source": [
        "target_col = 'label'\n",
        "\n",
        "if target_col in train_data.columns:\n",
        "    X = train_data.drop(target_col, axis=1)\n",
        "    y = train_data[target_col]\n",
        "\n",
        "    if target_col in test_data.columns:\n",
        "        X_test = test_data.drop(target_col, axis=1)\n",
        "    else:\n",
        "        X_test = test_data.copy() # Use .copy() to avoid SettingWithCopyWarning later\n",
        "\n",
        "    print(\"Data successfully split into training and testing sets.\")\n",
        "    print(f\"X (training features) shape: {X.shape}\")\n",
        "    print(f\"y (training target) shape: {y.shape}\")\n",
        "    print(f\"X_test (test features) shape: {X_test.shape}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: Target column '{target_col}' not found in the training data.\")\n",
        "    print(\"Please update the 'target_col' variable with the correct column name.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature selection applied.\n",
            "New shape of X (training features): (525887, 25)\n",
            "New shape of X_test (test features): (538150, 25)\n"
          ]
        }
      ],
      "source": [
        "# Define the list of features identified as most important through prior analysis.\n",
        "# This combines domain-specific features and data-driven anonymous features.\n",
        "\n",
        "features = [\n",
        "    # Top features identified from the referenced Kaggle notebook\n",
        "    \"X863\", \"X856\", \"X344\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
        "    \"X415\", \"X345\", \"X137\", \"X855\", \"X174\", \"X302\", \"X178\", \"X532\", \"X168\", \"X612\",\n",
        "    \n",
        "    # Core market microstructure features\n",
        "    \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\"\n",
        "]\n",
        "\n",
        "X = X[features]\n",
        "X_test = X_test[features]\n",
        "\n",
        "print(\"Feature selection applied.\")\n",
        "print(f\"New shape of X (training features): {X.shape}\")\n",
        "print(f\"New shape of X_test (test features): {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'__reduce_cython__'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_classification_threshold\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     FixedThresholdClassifier,\n\u001b[32m     10\u001b[39m     TunedThresholdClassifierCV,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_plot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ValidationCurveDisplay\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, ParameterGrid, ParameterSampler, RandomizedSearchCV\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_classification_threshold.py:17\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     BaseEstimator,\n\u001b[32m     11\u001b[39m     ClassifierMixin,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     clone,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     check_scoring,\n\u001b[32m     19\u001b[39m     get_scorer_names,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_scorer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     _CurveScorer,\n\u001b[32m     23\u001b[39m     _threshold_scores_to_class_labels,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, get_tags\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Score functions, performance metrics, pairwise metrics and distance computations.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_classification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     accuracy_score,\n\u001b[32m      9\u001b[39m     balanced_accuracy_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     zero_one_loss,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dist_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistanceMetric\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\cluster\\__init__.py:28\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bicluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m consensus_score\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_supervised\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     adjusted_mutual_info_score,\n\u001b[32m     14\u001b[39m     adjusted_rand_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     v_measure_score,\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_unsupervised\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     calinski_harabasz_score,\n\u001b[32m     30\u001b[39m     davies_bouldin_score,\n\u001b[32m     31\u001b[39m     silhouette_samples,\n\u001b[32m     32\u001b[39m     silhouette_score,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m __all__ = [\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madjusted_mutual_info_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madjusted_rand_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mv_measure_score\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:20\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _atol_for_type\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     Interval,\n\u001b[32m     17\u001b[39m     StrOptions,\n\u001b[32m     18\u001b[39m     validate_params,\n\u001b[32m     19\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VALID_METRICS, pairwise_distances, pairwise_distances_chunked\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_number_of_labels\u001b[39m(n_labels, n_samples):\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m        Number of samples.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples, check_non_negative\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pairwise_distances_reduction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArgKmin\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pairwise_fast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Utility Functions\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\__init__.py:94\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m \u001b[38;5;66;03m#    (see :class:`MiddleTermComputer{32,64}`).\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dispatcher\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     ArgKmin,\n\u001b[32m     96\u001b[39m     ArgKminClassMode,\n\u001b[32m     97\u001b[39m     BaseDistancesReductionDispatcher,\n\u001b[32m     98\u001b[39m     RadiusNeighbors,\n\u001b[32m     99\u001b[39m     RadiusNeighborsClassMode,\n\u001b[32m    100\u001b[39m     sqeuclidean_row_norms,\n\u001b[32m    101\u001b[39m )\n\u001b[32m    103\u001b[39m __all__ = [\n\u001b[32m    104\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mArgKmin\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    105\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mArgKminClassMode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msqeuclidean_row_norms\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m ]\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# ruff: noqa: E501\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:16\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dist_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     BOOL_METRICS,\n\u001b[32m     13\u001b[39m     METRIC_MAPPING64,\n\u001b[32m     14\u001b[39m     DistanceMetric,\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_argkmin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     ArgKmin32,\n\u001b[32m     18\u001b[39m     ArgKmin64,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_argkmin_classmode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     ArgKminClassMode32,\n\u001b[32m     22\u001b[39m     ArgKminClassMode64,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n",
            "\u001b[36mFile \u001b[39m\u001b[32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:1\u001b[39m, in \u001b[36minit sklearn.metrics._pairwise_distances_reduction._argkmin\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: '__reduce_cython__'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.base import clone\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"\n",
        "    A wrapper class to simplify cross-validated model training, prediction,\n",
        "    and evaluation. It handles out-of-fold predictions and aggregates scores.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, cv, metric, task=\"regression\", metric_precision=6):\n",
        "        self.model = model\n",
        "        self.cv = cv\n",
        "        self.metric = metric\n",
        "        self.task = task\n",
        "        self.metric_precision = metric_precision\n",
        "        self.models_ = []\n",
        "        self.fold_scores = []\n",
        "        self.oof_preds = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fits the model using the provided cross-validation strategy.\n",
        "        It stores the trained model for each fold and computes out-of-fold predictions.\n",
        "        \"\"\"\n",
        "        self.models_ = []\n",
        "        self.oof_preds = np.zeros(len(X))\n",
        "        \n",
        "        # Check if input data is a pandas DataFrame or Series\n",
        "        is_pandas = hasattr(X, 'iloc')\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y)):\n",
        "            print(f\"--- Fold {fold+1} ---\")\n",
        "\n",
        "            if is_pandas:\n",
        "                X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "                X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
        "            else:  # Assume numpy array\n",
        "                X_train, y_train = X[train_idx], y[train_idx]\n",
        "                X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "            fold_model = clone(self.model)\n",
        "            fold_model.fit(X_train, y_train)\n",
        "            self.models_.append(fold_model)\n",
        "\n",
        "            val_preds = fold_model.predict(X_val)\n",
        "            self.oof_preds[val_idx] = val_preds\n",
        "\n",
        "            score, _ = self.metric(y_val, val_preds)\n",
        "            self.fold_scores.append(round(score, self.metric_precision))\n",
        "            print(f\"Fold {fold+1} Score: {self.fold_scores[-1]}\")\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Generates test set predictions by averaging the predictions \n",
        "        from all models trained during cross-validation.\n",
        "        \"\"\"\n",
        "        if not self.models_:\n",
        "            raise RuntimeError(\"The trainer has not been fitted yet. Call .fit() before .predict().\")\n",
        "\n",
        "        test_predictions = np.zeros(len(X_test))\n",
        "        for model in self.models_:\n",
        "            test_predictions += model.predict(X_test)\n",
        "        \n",
        "        return test_predictions / len(self.models_)\n",
        "\n",
        "# Define XGBoost model parameters from your notebook\n",
        "xgb_params = {\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"device\": \"gpu\",\n",
        "    \"colsample_bylevel\": 0.4778,\n",
        "    \"colsample_bynode\": 0.3628,\n",
        "    \"colsample_bytree\": 0.7107,\n",
        "    \"gamma\": 1.7095,\n",
        "    \"learning_rate\": 0.02213,\n",
        "    \"max_depth\": 20,\n",
        "    \"max_leaves\": 12,\n",
        "    \"min_child_weight\": 16,\n",
        "    \"n_estimators\": 1667,\n",
        "    \"subsample\": 0.06567,\n",
        "    \"reg_alpha\": 39.3524,\n",
        "    \"reg_lambda\": 75.4484,\n",
        "    \"verbosity\": 0,\n",
        "    \"random_state\": 42,\n",
        "    \"n_jobs\": -1\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to store results for different models\n",
        "fold_scores = {}\n",
        "overall_scores = {}\n",
        "oof_preds = {}\n",
        "test_preds = {}\n",
        "\n",
        "# Instantiate the trainer with the XGBoost regressor and parameters\n",
        "xgb_trainer = Trainer(\n",
        "    model=XGBRegressor(**xgb_params),\n",
        "    cv=KFold(n_splits=5, shuffle=False),\n",
        "    metric=pearsonr,\n",
        "    task=\"regression\",\n",
        "    metric_precision=6\n",
        ")\n",
        "\n",
        "# Assuming X, y, and X_test are defined and available in your environment\n",
        "# Fit the model and generate out-of-fold predictions\n",
        "xgb_trainer.fit(X, y)\n",
        "\n",
        "# Store the results\n",
        "fold_scores[\"XGBoost\"] = xgb_trainer.fold_scores\n",
        "overall_scores[\"XGBoost\"] = [pearsonr(xgb_trainer.oof_preds, y)[0]]\n",
        "oof_preds[\"XGBoost\"] = xgb_trainer.oof_preds\n",
        "test_preds[\"XGBoost\"] = xgb_trainer.predict(X_test)\n",
        "\n",
        "# Print a summary of the training results\n",
        "print(\"\\n--- XGBoost Training Summary ---\")\n",
        "print(f\"Fold Scores: {fold_scores['XGBoost']}\")\n",
        "print(f\"Overall OOF Score (Pearson): {overall_scores['XGBoost'][0]:.6f}\")\n",
        "print(f\"Test predictions shape: {test_preds['XGBoost'].shape}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
