{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March Madness Prediction\n",
    "\n",
    "## Overview\n",
    "\n",
    "###\n",
    "\n",
    "### Goal\n",
    "Submissions are based on the Brier Score, the goal will be to minimize the brier score between the predicted probabilities and the actual game outcomes. The Brier score measures the accuracy of probablistic predition, in this case the mean square error. \n",
    "\n",
    "The brier score can be thought of as a cost function that measures the average squared difference between the predicted probabilities and the actual outcomes.\n",
    "\n",
    "$$\n",
    "Brier = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2\n",
    "$$\n",
    "\n",
    "where $p_i$ is the predicted probability of the event and $o_i$ is the actual outcome. The Brier score can span across all items in a set of N predictions.\n",
    "\n",
    "Therefore, minimizing the Brier score will result in a more accurate prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T03:40:34.483727Z",
     "iopub.status.busy": "2025-03-23T03:40:34.483364Z",
     "iopub.status.idle": "2025-03-23T03:40:34.490041Z",
     "shell.execute_reply": "2025-03-23T03:40:34.488948Z",
     "shell.execute_reply.started": "2025-03-23T03:40:34.483701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sp\n",
    "import xgboost as xgb\n",
    "import sklearn as sk\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import log_loss, mean_absolute_error, brier_score_loss\n",
    "\n",
    "# Style\n",
    "plt.style.use(\"dark_background\")\n",
    "px.defaults.template = 'plotly_dark'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Set up a data dictionary that will store the data for each file, this will make it easier to access data from the csvs. Not all files are used in the prediction process, but they are included for completeness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:05:32.717275Z",
     "iopub.status.busy": "2025-03-23T03:05:32.716608Z",
     "iopub.status.idle": "2025-03-23T03:05:38.563274Z",
     "shell.execute_reply": "2025-03-23T03:05:38.562315Z",
     "shell.execute_reply.started": "2025-03-23T03:05:32.717234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "path = 'data/**'\n",
    "data = {p.split('/')[-1].split('.')[0] : pd.read_csv(p, encoding='latin-1') for p in glob.glob(path)}\n",
    "\n",
    "# Create Teams Dataframe\n",
    "teams = pd.concat([data['MTeams'], data['WTeams']])\n",
    "teams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\n",
    "teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "\n",
    "# Create Season Dataframes and S/T Flag\n",
    "season_compact_results = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']]).assign(ST='S')\n",
    "season_detailed_results = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']]).assign(ST='S')\n",
    "tourney_compact_results = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']]).assign(ST='T')\n",
    "tourney_detailed_results = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']]).assign(ST='T')\n",
    "\n",
    "# Create Tourney Dataframes\n",
    "lots = pd.concat([data['MNCAATourneySlots'], data['WNCAATourneySlots']])\n",
    "seeds = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\n",
    "seeds['SeedValue'] = seeds['Seed'].str.extract(r'(\\d+)').astype(int)\n",
    "seeds_dict = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}\n",
    "game_cities = pd.concat([data['MGameCities'], data['WGameCities']])\n",
    "seasons = pd.concat([data['MSeasons'], data['WSeasons']])\n",
    "cities = data['Cities']\n",
    "\n",
    "# Create Sample Submission Dataframe\n",
    "sub = data['SampleSubmissionStage1']\n",
    "del data\n",
    "\n",
    "# Seeds Dictionary\n",
    "seeds = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:05:38.565441Z",
     "iopub.status.busy": "2025-03-23T03:05:38.565121Z",
     "iopub.status.idle": "2025-03-23T03:05:56.243661Z",
     "shell.execute_reply": "2025-03-23T03:05:56.242573Z",
     "shell.execute_reply.started": "2025-03-23T03:05:38.565412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create Detailed Results Dataframe\n",
    "all_detailed_results = pd.concat([season_detailed_results, tourney_detailed_results])\n",
    "all_detailed_results.reset_index(drop=True, inplace=True)\n",
    "all_detailed_results['WLoc'] = all_detailed_results['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
    "\n",
    "# Add additional features to detailed results\n",
    "all_detailed_results['ID'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "all_detailed_results['IDTeams'] = all_detailed_results.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "all_detailed_results['Team1'] = all_detailed_results.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
    "all_detailed_results['Team2'] = all_detailed_results.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
    "all_detailed_results['IDTeam1'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "all_detailed_results['IDTeam2'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "\n",
    "all_detailed_results['Team1Seed'] = all_detailed_results['IDTeam1'].map(seeds).fillna(0)\n",
    "all_detailed_results['Team2Seed'] = all_detailed_results['IDTeam2'].map(seeds).fillna(0)\n",
    "\n",
    "all_detailed_results['ScoreDiff'] = all_detailed_results['WScore'] - all_detailed_results['LScore']\n",
    "all_detailed_results['Pred'] = all_detailed_results.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
    "all_detailed_results['ScoreDiffNorm'] = all_detailed_results.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\n",
    "all_detailed_results['SeedDiff'] = all_detailed_results['Team1Seed'] - all_detailed_results['Team2Seed'] \n",
    "all_detailed_results = all_detailed_results.fillna(-1)\n",
    "\n",
    "# Add derived features to detaifled results\n",
    "all_detailed_results['ScoreDiff'] = all_detailed_results['WScore'] - all_detailed_results['LScore']\n",
    "all_detailed_results['HomeAdvantage'] = (all_detailed_results['WLoc'] == 2).astype(int)\n",
    "\n",
    "# Calculate shooting percentages (handling division by zero)\n",
    "all_detailed_results['WFGPct'] = np.where(all_detailed_results['WFGA'] > 0, \n",
    "                                        all_detailed_results['WFGM'] / all_detailed_results['WFGA'], 0)\n",
    "all_detailed_results['WFG3Pct'] = np.where(all_detailed_results['WFGA3'] > 0, \n",
    "                                        all_detailed_results['WFGM3'] / all_detailed_results['WFGA3'], 0)\n",
    "all_detailed_results['WFTPct'] = np.where(all_detailed_results['WFTA'] > 0, \n",
    "                                        all_detailed_results['WFTM'] / all_detailed_results['WFTA'], 0)\n",
    "all_detailed_results['LFGPct'] = np.where(all_detailed_results['LFGA'] > 0, \n",
    "                                        all_detailed_results['LFGM'] / all_detailed_results['LFGA'], 0)\n",
    "all_detailed_results['LFG3Pct'] = np.where(all_detailed_results['LFGA3'] > 0, \n",
    "                                        all_detailed_results['LFGM3'] / all_detailed_results['LFGA3'], 0)\n",
    "all_detailed_results['LFTPct'] = np.where(all_detailed_results['LFTA'] > 0, \n",
    "                                        all_detailed_results['LFTM'] / all_detailed_results['LFTA'], 0)\n",
    "\n",
    "# Add statistical differences\n",
    "all_detailed_results['ReboundDiff'] = (all_detailed_results['WOR'] + all_detailed_results['WDR']) - \\\n",
    "                                    (all_detailed_results['LOR'] + all_detailed_results['LDR'])\n",
    "all_detailed_results['AssistDiff'] = all_detailed_results['WAst'] - all_detailed_results['LAst']\n",
    "all_detailed_results['TurnoverDiff'] = all_detailed_results['WTO'] - all_detailed_results['LTO']\n",
    "all_detailed_results['StealDiff'] = all_detailed_results['WStl'] - all_detailed_results['LStl']\n",
    "all_detailed_results['BlockDiff'] = all_detailed_results['WBlk'] - all_detailed_results['LBlk']\n",
    "all_detailed_results['FoulDiff'] = all_detailed_results['WPF'] - all_detailed_results['LPF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:05:56.245219Z",
     "iopub.status.busy": "2025-03-23T03:05:56.244836Z",
     "iopub.status.idle": "2025-03-23T03:06:16.162692Z",
     "shell.execute_reply": "2025-03-23T03:06:16.161843Z",
     "shell.execute_reply.started": "2025-03-23T03:05:56.245182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl',\n",
    " 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl',\n",
    " 'LBlk', 'LPF']\n",
    "c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "gb = all_detailed_results.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "gb.columns = [''.join(c) + '_c_score' for c in gb.columns]\n",
    "\n",
    "sub['WLoc'] = 3\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['Season'].astype(int)\n",
    "sub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\n",
    "sub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\n",
    "sub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
    "sub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "sub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "sub['Team1Seed'] = sub['IDTeam1'].map(seeds).fillna(0)\n",
    "sub['Team2Seed'] = sub['IDTeam2'].map(seeds).fillna(0)\n",
    "sub['SeedDiff'] = sub['Team1Seed'] - sub['Team2Seed'] \n",
    "sub = sub.fillna(-1)\n",
    "\n",
    "games = pd.merge(all_detailed_results, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "sub = pd.merge(sub, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "\n",
    "col = [c for c in games.columns if c not in ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc'] + c_score_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:40:44.807278Z",
     "iopub.status.busy": "2025-03-23T03:40:44.806961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training main model...\n",
      "Log Loss: 0.2836254754686792\n",
      "Mean Absolute Error: 0.229211302581863\n",
      "Brier Score: 0.07603705889507632\n",
      "Cross-validated MSE: 0.21865491983811386\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean')  \n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = games[col].fillna(-1)\n",
    "missing_cols = set(col) - set(sub.columns)\n",
    "for c in missing_cols:\n",
    "    sub[c] = 0\n",
    "\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Main prediction model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=5000,         # Number of boosting rounds\n",
    "    learning_rate=0.05,       # Smaller learning rate for better generalization\n",
    "    max_depth=6,              # Control model complexity\n",
    "    min_child_weight=3,       # Helps prevent overfitting\n",
    "    subsample=0.8,            # Use 80% of data for each tree\n",
    "    colsample_bytree=0.8,     # Use 80% of features for each tree\n",
    "    objective='binary:logistic',  # Binary classification with probability output\n",
    "    random_state=42,\n",
    "    n_jobs=-1                 # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Train the main model\n",
    "print(\"\\nTraining main model...\")\n",
    "model.fit(X_scaled, games['Pred'])\n",
    "\n",
    "pred = model.predict(X_scaled).clip(0.001, 0.999)\n",
    "\n",
    "\n",
    "print(f'Log Loss: {log_loss(games[\"Pred\"], pred)}')\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(games[\"Pred\"], pred)}')\n",
    "print(f'Brier Score: {brier_score_loss(games[\"Pred\"], pred)}')\n",
    "\n",
    "cv_scores = cross_val_score(model, X_scaled, games['Pred'], cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'Cross-validated MSE: {-cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sub_X: (507108, 234)\n",
      "Creating imputed data...\n"
     ]
    }
   ],
   "source": [
    "# causing crash perhaps?\n",
    "sub_X = sub[col].fillna(-1)\n",
    "# Add print statements to debug\n",
    "print(\"Shape of sub_X:\", sub_X.shape)\n",
    "print(\"Creating imputed data...\")\n",
    "\n",
    "# todo: investigate why imputer transform on sub_X is causing a crash\n",
    "sub_X_imputed = imputer.transform(sub_X)\n",
    "print(\"Scaling data...\")\n",
    "sub_X_scaled = scaler.transform(sub_X_imputed)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "# Store predictions in a variable first\n",
    "predictions = model.predict(sub_X_scaled).clip(0.001, 0.999)\n",
    "print(\"Prediction shape:\", predictions.shape)\n",
    "\n",
    "# Assign to dataframe\n",
    "sub['Pred'] = predictions\n",
    "print(\"Saving to CSV...\")\n",
    "sub[['ID', 'Pred']].to_csv('submission.csv', index=False)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11484718,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
