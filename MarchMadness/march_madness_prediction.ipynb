{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March Madness Prediction\n",
    "\n",
    "## Overview\n",
    "\n",
    "###\n",
    "\n",
    "### Goal\n",
    "Submissions are based on the Brier Score, the goal will be to minimize the brier score between the predicted probabilities and the actual game outcomes. The Brier score measures the accuracy of probablistic predition, in this case the mean square error. \n",
    "\n",
    "The brier score can be thought of as a cost function that measures the average squared difference between the predicted probabilities and the actual outcomes.\n",
    "\n",
    "$$\n",
    "Brier = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2\n",
    "$$\n",
    "\n",
    "where $p_i$ is the predicted probability of the event and $o_i$ is the actual outcome. The Brier score can span across all items in a set of N predictions.\n",
    "\n",
    "Therefore, minimizing the Brier score will result in a more accurate prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T03:40:34.483727Z",
     "iopub.status.busy": "2025-03-23T03:40:34.483364Z",
     "iopub.status.idle": "2025-03-23T03:40:34.490041Z",
     "shell.execute_reply": "2025-03-23T03:40:34.488948Z",
     "shell.execute_reply.started": "2025-03-23T03:40:34.483701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sp\n",
    "import xgboost as xgb\n",
    "import sklearn as sk\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import log_loss, mean_absolute_error, brier_score_loss\n",
    "\n",
    "# Style\n",
    "plt.style.use(\"dark_background\")\n",
    "px.defaults.template = 'plotly_dark'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Set up a data dictionary that will store the data for each file, this will make it easier to access data from the csvs. Not all files are used in the prediction process, but they are included for completeness.\n",
    "\n",
    "Additionaly I am going to create a Sample Submission Dataframe that will be used to store the predictions for the sample submission, this will be populated with the predictions from the model later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:05:32.717275Z",
     "iopub.status.busy": "2025-03-23T03:05:32.716608Z",
     "iopub.status.idle": "2025-03-23T03:05:38.563274Z",
     "shell.execute_reply": "2025-03-23T03:05:38.562315Z",
     "shell.execute_reply.started": "2025-03-23T03:05:32.717234Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 CSV files\n",
      "Loading Cities...\n",
      "Loading Conferences...\n",
      "Loading MConferenceTourneyGames...\n",
      "Loading MGameCities...\n",
      "Loading MMasseyOrdinals...\n",
      "Loading MNCAATourneyCompactResults...\n",
      "Loading MNCAATourneyDetailedResults...\n",
      "Loading MNCAATourneySeedRoundSlots...\n",
      "Loading MNCAATourneySeeds...\n",
      "Loading MNCAATourneySlots...\n",
      "Loading MRegularSeasonCompactResults...\n",
      "Loading MRegularSeasonDetailedResults...\n",
      "Loading MSeasons...\n",
      "Loading MSecondaryTourneyCompactResults...\n",
      "Loading MSecondaryTourneyTeams...\n",
      "Loading MTeamCoaches...\n",
      "Loading MTeamConferences...\n",
      "Loading MTeams...\n",
      "Loading MTeamSpellings...\n",
      "Loading SampleSubmissionStage1...\n",
      "Loading SampleSubmissionStage2...\n",
      "Loading SeedBenchmarkStage1...\n",
      "Loading WConferenceTourneyGames...\n",
      "Loading WGameCities...\n",
      "Loading WNCAATourneyCompactResults...\n",
      "Loading WNCAATourneyDetailedResults...\n",
      "Loading WNCAATourneySeeds...\n",
      "Loading WNCAATourneySlots...\n",
      "Loading WRegularSeasonCompactResults...\n",
      "Loading WRegularSeasonDetailedResults...\n",
      "Loading WSeasons...\n",
      "Loading WSecondaryTourneyCompactResults...\n",
      "Loading WSecondaryTourneyTeams...\n",
      "Loading WTeamConferences...\n",
      "Loading WTeams...\n",
      "Loading WTeamSpellings...\n",
      "Loaded data files: ['Cities', 'Conferences', 'MConferenceTourneyGames', 'MGameCities', 'MMasseyOrdinals', 'MNCAATourneyCompactResults', 'MNCAATourneyDetailedResults', 'MNCAATourneySeedRoundSlots', 'MNCAATourneySeeds', 'MNCAATourneySlots', 'MRegularSeasonCompactResults', 'MRegularSeasonDetailedResults', 'MSeasons', 'MSecondaryTourneyCompactResults', 'MSecondaryTourneyTeams', 'MTeamCoaches', 'MTeamConferences', 'MTeams', 'MTeamSpellings', 'SampleSubmissionStage1', 'SampleSubmissionStage2', 'SeedBenchmarkStage1', 'WConferenceTourneyGames', 'WGameCities', 'WNCAATourneyCompactResults', 'WNCAATourneyDetailedResults', 'WNCAATourneySeeds', 'WNCAATourneySlots', 'WRegularSeasonCompactResults', 'WRegularSeasonDetailedResults', 'WSeasons', 'WSecondaryTourneyCompactResults', 'WSecondaryTourneyTeams', 'WTeamConferences', 'WTeams', 'WTeamSpellings']\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "import os\n",
    "\n",
    "# Load Data - Use forward slashes or os.path.join for cross-platform compatibility\n",
    "path = '../data/*.csv'\n",
    "try:\n",
    "    csv_files = glob.glob(path)\n",
    "    print(f\"Found {len(csv_files)} CSV files\")\n",
    "    if not csv_files:\n",
    "        # Try alternative path for Windows\n",
    "        path = '../data\\\\*.csv'\n",
    "        csv_files = glob.glob(path)\n",
    "        print(f\"Found {len(csv_files)} CSV files with Windows path\")\n",
    "    \n",
    "    data = {}\n",
    "    for p in csv_files:\n",
    "        # Extract filename without extension\n",
    "        filename = p.split('/')[-1].split('\\\\')[-1].split('.')[0]  # Handle both separators\n",
    "        print(f\"Loading {filename}...\")\n",
    "        data[filename] = pd.read_csv(p, encoding='latin-1')\n",
    "    \n",
    "    print(f\"Loaded data files: {list(data.keys())}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "\n",
    "# Create Teams Dataframe\n",
    "teams = pd.concat([data['MTeams'], data['WTeams']])\n",
    "teams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\n",
    "teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "\n",
    "# Create Season Dataframes and S/T Flag\n",
    "season_compact_results = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']]).assign(ST='S')\n",
    "season_detailed_results = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']]).assign(ST='S')\n",
    "tourney_compact_results = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']]).assign(ST='T')\n",
    "tourney_detailed_results = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']]).assign(ST='T')\n",
    "\n",
    "# Create Tourney Dataframes\n",
    "lots = pd.concat([data['MNCAATourneySlots'], data['WNCAATourneySlots']])\n",
    "seeds = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\n",
    "seeds['SeedValue'] = seeds['Seed'].str.extract(r'(\\d+)').astype(int)\n",
    "seeds_dict = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}\n",
    "game_cities = pd.concat([data['MGameCities'], data['WGameCities']])\n",
    "seasons = pd.concat([data['MSeasons'], data['WSeasons']])\n",
    "cities = data['Cities']\n",
    "\n",
    "# Create Sample Submission Dataframe\n",
    "sub = data['SampleSubmissionStage1']\n",
    "del data\n",
    "\n",
    "# Seeds Dictionary\n",
    "seeds = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we concatinate the regular season and tournament detailed results into a single dataframe. We also add additional features to the dataframe that will be used in the model.\n",
    "\n",
    "This includes derived features such as the score difference, home advantage, and shooting percentages. We also add the derived features to the detailed results dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:05:38.565441Z",
     "iopub.status.busy": "2025-03-23T03:05:38.565121Z",
     "iopub.status.idle": "2025-03-23T03:05:56.243661Z",
     "shell.execute_reply": "2025-03-23T03:05:56.242573Z",
     "shell.execute_reply.started": "2025-03-23T03:05:38.565412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create Detailed Results Dataframe\n",
    "all_detailed_results = pd.concat([season_detailed_results, tourney_detailed_results])\n",
    "all_detailed_results.reset_index(drop=True, inplace=True)\n",
    "all_detailed_results['WLoc'] = all_detailed_results['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
    "\n",
    "# Add additional features to detailed results\n",
    "all_detailed_results['ID'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "all_detailed_results['IDTeams'] = all_detailed_results.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "all_detailed_results['Team1'] = all_detailed_results.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
    "all_detailed_results['Team2'] = all_detailed_results.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
    "all_detailed_results['IDTeam1'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "all_detailed_results['IDTeam2'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "\n",
    "all_detailed_results['Team1Seed'] = all_detailed_results['IDTeam1'].map(seeds).fillna(0)\n",
    "all_detailed_results['Team2Seed'] = all_detailed_results['IDTeam2'].map(seeds).fillna(0)\n",
    "\n",
    "all_detailed_results['ScoreDiff'] = all_detailed_results['WScore'] - all_detailed_results['LScore']\n",
    "all_detailed_results['Pred'] = all_detailed_results.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
    "all_detailed_results['ScoreDiffNorm'] = all_detailed_results.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\n",
    "all_detailed_results['SeedDiff'] = all_detailed_results['Team1Seed'] - all_detailed_results['Team2Seed'] \n",
    "all_detailed_results = all_detailed_results.fillna(-1)\n",
    "\n",
    "# Add derived features to detaifled results\n",
    "all_detailed_results['ScoreDiff'] = all_detailed_results['WScore'] - all_detailed_results['LScore']\n",
    "all_detailed_results['HomeAdvantage'] = (all_detailed_results['WLoc'] == 2).astype(int)\n",
    "\n",
    "# Calculate shooting percentages (handling division by zero)\n",
    "all_detailed_results['WFGPct'] = np.where(all_detailed_results['WFGA'] > 0, \n",
    "                                        all_detailed_results['WFGM'] / all_detailed_results['WFGA'], 0)\n",
    "all_detailed_results['WFG3Pct'] = np.where(all_detailed_results['WFGA3'] > 0, \n",
    "                                        all_detailed_results['WFGM3'] / all_detailed_results['WFGA3'], 0)\n",
    "all_detailed_results['WFTPct'] = np.where(all_detailed_results['WFTA'] > 0, \n",
    "                                        all_detailed_results['WFTM'] / all_detailed_results['WFTA'], 0)\n",
    "all_detailed_results['LFGPct'] = np.where(all_detailed_results['LFGA'] > 0, \n",
    "                                        all_detailed_results['LFGM'] / all_detailed_results['LFGA'], 0)\n",
    "all_detailed_results['LFG3Pct'] = np.where(all_detailed_results['LFGA3'] > 0, \n",
    "                                        all_detailed_results['LFGM3'] / all_detailed_results['LFGA3'], 0)\n",
    "all_detailed_results['LFTPct'] = np.where(all_detailed_results['LFTA'] > 0, \n",
    "                                        all_detailed_results['LFTM'] / all_detailed_results['LFTA'], 0)\n",
    "\n",
    "# Add statistical differences\n",
    "all_detailed_results['ReboundDiff'] = (all_detailed_results['WOR'] + all_detailed_results['WDR']) - \\\n",
    "                                    (all_detailed_results['LOR'] + all_detailed_results['LDR'])\n",
    "all_detailed_results['AssistDiff'] = all_detailed_results['WAst'] - all_detailed_results['LAst']\n",
    "all_detailed_results['TurnoverDiff'] = all_detailed_results['WTO'] - all_detailed_results['LTO']\n",
    "all_detailed_results['StealDiff'] = all_detailed_results['WStl'] - all_detailed_results['LStl']\n",
    "all_detailed_results['BlockDiff'] = all_detailed_results['WBlk'] - all_detailed_results['LBlk']\n",
    "all_detailed_results['FoulDiff'] = all_detailed_results['WPF'] - all_detailed_results['LPF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to begin setting up the data for the model. We will group the detailed results by the IDTeams and then aggregate the data. We will also create a sample submission dataframe that will be used to store the predictions for the sample submission, this will be populated with the predictions from the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:05:56.245219Z",
     "iopub.status.busy": "2025-03-23T03:05:56.244836Z",
     "iopub.status.idle": "2025-03-23T03:06:16.162692Z",
     "shell.execute_reply": "2025-03-23T03:06:16.161843Z",
     "shell.execute_reply.started": "2025-03-23T03:05:56.245182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl',\n",
    " 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl',\n",
    " 'LBlk', 'LPF']\n",
    "c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "gb = all_detailed_results.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "gb.columns = [''.join(c) + '_c_score' for c in gb.columns]\n",
    "\n",
    "sub['WLoc'] = 3\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['Season'].astype(int)\n",
    "sub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\n",
    "sub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\n",
    "sub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
    "sub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "sub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "sub['Team1Seed'] = sub['IDTeam1'].map(seeds).fillna(0)\n",
    "sub['Team2Seed'] = sub['IDTeam2'].map(seeds).fillna(0)\n",
    "sub['SeedDiff'] = sub['Team1Seed'] - sub['Team2Seed'] \n",
    "sub = sub.fillna(-1)\n",
    "\n",
    "games = pd.merge(all_detailed_results, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "sub = pd.merge(sub, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "\n",
    "col = [c for c in games.columns if c not in ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc'] + c_score_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Now we can begin training the model. We will use a simple XGBoost model to predict the outcome of the game. We will also use a simple imputer to fill in the missing values and a standard scaler to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T03:40:44.807278Z",
     "iopub.status.busy": "2025-03-23T03:40:44.806961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training main model...\n",
      "Log Loss: 0.2801704227848632\n",
      "Mean Absolute Error: 0.22647324770944763\n",
      "Brier Score: 0.07499056544694568\n",
      "Cross-validated MSE: 0.21594714085560499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import brier_score_loss, log_loss\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = games[col].fillna(-1)\n",
    "missing_cols = set(col) - set(sub.columns)\n",
    "for c in missing_cols:\n",
    "    sub[c] = 0\n",
    "\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Fixed: Use XGBClassifier for probability prediction\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=3000,         # Reduced from 5000 for faster training\n",
    "    learning_rate=0.05,        # Learning rate for gradient boosting\n",
    "    max_depth=6,               # Control model complexity\n",
    "    min_child_weight=3,        # Helps prevent overfitting\n",
    "    subsample=0.8,             # Use 80% of data for each tree\n",
    "    colsample_bytree=0.8,      # Use 80% of features for each tree\n",
    "    objective='binary:logistic', # Proper binary classification objective\n",
    "    random_state=42,\n",
    "    n_jobs=-1,                 # Use all CPU cores\n",
    "    eval_metric='logloss'      # Use log loss for evaluation\n",
    ")\n",
    "\n",
    "# Implement time-aware cross-validation\n",
    "def time_aware_cv(model, X, y, seasons, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform time-aware cross-validation where we train on earlier seasons\n",
    "    and validate on later seasons to prevent data leakage.\n",
    "    \"\"\"\n",
    "    unique_seasons = sorted(seasons.unique())\n",
    "    cv_scores = []\n",
    "    \n",
    "    # Calculate split points for time-based CV\n",
    "    season_splits = []\n",
    "    split_size = len(unique_seasons) // (n_splits + 1)\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end_idx = split_size * (i + 2)  # End of training seasons\n",
    "        val_start_idx = train_end_idx\n",
    "        val_end_idx = min(train_end_idx + split_size, len(unique_seasons))\n",
    "        \n",
    "        if val_end_idx > len(unique_seasons):\n",
    "            break\n",
    "            \n",
    "        train_seasons = unique_seasons[:train_end_idx]\n",
    "        val_seasons = unique_seasons[val_start_idx:val_end_idx]\n",
    "        \n",
    "        season_splits.append((train_seasons, val_seasons))\n",
    "    \n",
    "    print(f\"Time-aware CV with {len(season_splits)} splits:\")\n",
    "    \n",
    "    for i, (train_seasons, val_seasons) in enumerate(season_splits):\n",
    "        # Create train/val masks\n",
    "        train_mask = seasons.isin(train_seasons)\n",
    "        val_mask = seasons.isin(val_seasons)\n",
    "        \n",
    "        if train_mask.sum() == 0 or val_mask.sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        X_train_fold, X_val_fold = X[train_mask], X[val_mask]\n",
    "        y_train_fold, y_val_fold = y[train_mask], y[val_mask]\n",
    "        \n",
    "        # Fit model on training fold\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on validation fold\n",
    "        y_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "        y_pred_proba = np.clip(y_pred_proba, 0.001, 0.999)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        brier = brier_score_loss(y_val_fold, y_pred_proba)\n",
    "        logloss = log_loss(y_val_fold, y_pred_proba)\n",
    "        \n",
    "        cv_scores.append(brier)\n",
    "        \n",
    "        print(f\"  Fold {i+1}: Train seasons {train_seasons[0]}-{train_seasons[-1]} | \"\n",
    "              f\"Val seasons {val_seasons[0]}-{val_seasons[-1]} | \"\n",
    "              f\"Brier: {brier:.4f} | LogLoss: {logloss:.4f}\")\n",
    "    \n",
    "    return cv_scores\n",
    "\n",
    "# Perform time-aware cross-validation\n",
    "print(\"\\nPerforming time-aware cross-validation...\")\n",
    "cv_brier_scores = time_aware_cv(model, X_scaled, games['Pred'], games['Season'])\n",
    "\n",
    "print(f\"\\nTime-aware CV Results:\")\n",
    "print(f\"Mean Brier Score: {np.mean(cv_brier_scores):.4f} Â± {np.std(cv_brier_scores):.4f}\")\n",
    "\n",
    "# Train the final model on all data\n",
    "print(\"\\nTraining final model on all data...\")\n",
    "model.fit(X_scaled, games['Pred'])\n",
    "\n",
    "# Get predictions with proper probability output\n",
    "pred_proba = model.predict_proba(X_scaled)[:, 1]  # Get probability of class 1\n",
    "pred_proba = np.clip(pred_proba, 0.001, 0.999)\n",
    "\n",
    "print(f'\\nFinal Model Performance on Training Data:')\n",
    "print(f'Log Loss: {log_loss(games[\"Pred\"], pred_proba):.4f}')\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(games[\"Pred\"], pred_proba):.4f}')\n",
    "print(f'Brier Score: {brier_score_loss(games[\"Pred\"], pred_proba):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Model\n",
    "Training main model...\n",
    "Log Loss: 0.2801704227848632\n",
    "Mean Absolute Error: 0.22647324770944763\n",
    "Brier Score: 0.07499056544694568\n",
    "Cross-validated MSE: 0.21594714085560499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sub_X: (507108, 234)\n",
      "Creating imputed data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating imputed data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Transform using fitted imputer and scaler\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m sub_X_imputed = \u001b[43mimputer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mScaling data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m sub_X_scaled = scaler.transform(sub_X_imputed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:609\u001b[39m, in \u001b[36mSimpleImputer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Impute all missing values in `X`.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    605\u001b[39m \u001b[33;03m    `X` with imputed values.\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    607\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m statistics = \u001b[38;5;28mself\u001b[39m.statistics_\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.shape[\u001b[32m1\u001b[39m] != statistics.shape[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:344\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    341\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcould not convert\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1115\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmay_share_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_orig\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1116\u001b[39m             array = _asarray_with_order(\n\u001b[32m   1117\u001b[39m                 array, dtype=dtype, order=order, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, xp=xp\n\u001b[32m   1118\u001b[39m             )\n\u001b[32m   1119\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1120\u001b[39m         \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2165\u001b[39m, in \u001b[36mNDFrame.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mgr.is_single_block \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.empty:\n\u001b[32m   2153\u001b[39m     \u001b[38;5;66;03m# check this manually, otherwise ._values will already return a copy\u001b[39;00m\n\u001b[32m   2154\u001b[39m     \u001b[38;5;66;03m# and np.array(values, copy=False) will not raise a warning\u001b[39;00m\n\u001b[32m   2155\u001b[39m     warnings.warn(\n\u001b[32m   2156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mStarting with NumPy 2.0, the behavior of the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keyword has \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mchanged and passing \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcopy=False\u001b[39m\u001b[33m'\u001b[39m\u001b[33m raises an error when returning \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2163\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   2164\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2165\u001b[39m values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m     \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m   2168\u001b[39m     arr = np.asarray(values, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:1127\u001b[39m, in \u001b[36mDataFrame._values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1125\u001b[39m blocks = mgr.blocks\n\u001b[32m   1126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) != \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m)\n\u001b[32m   1129\u001b[39m arr = blocks[\u001b[32m0\u001b[39m].values\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m   1131\u001b[39m     \u001b[38;5;66;03m# non-2D ExtensionArray\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:12671\u001b[39m, in \u001b[36mDataFrame.values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  12597\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m  12598\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m  12599\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  12600\u001b[39m \u001b[33;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[32m  12601\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m  12669\u001b[39m \u001b[33;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[32m  12670\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12671\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[39m, in \u001b[36mBlockManager.as_array\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1692\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[32m   1696\u001b[39m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cardo\\Workspace\\kaggle-comp\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1737\u001b[39m, in \u001b[36mBlockManager._interleave\u001b[39m\u001b[34m(self, dtype, na_value)\u001b[39m\n\u001b[32m   1735\u001b[39m         arr = blk.get_values(dtype)\n\u001b[32m   1736\u001b[39m         result[rl.indexer] = arr\n\u001b[32m-> \u001b[39m\u001b[32m1737\u001b[39m         itemmask[rl.indexer] = \u001b[32m1\u001b[39m\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Fill in missing values for submission data\n",
    "sub_X = sub[col].fillna(-1)\n",
    "\n",
    "print(\"Shape of sub_X:\", sub_X.shape)\n",
    "print(\"Creating imputed data...\")\n",
    "\n",
    "# Transform using fitted imputer and scaler\n",
    "sub_X_imputed = imputer.transform(sub_X)\n",
    "print(\"Scaling data...\")\n",
    "sub_X_scaled = scaler.transform(sub_X_imputed)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "# Use predict_proba for proper probability output with XGBClassifier\n",
    "predictions = model.predict_proba(sub_X_scaled)[:, 1]  # Get probability of class 1\n",
    "predictions = np.clip(predictions, 0.001, 0.999)\n",
    "print(\"Prediction shape:\", predictions.shape)\n",
    "\n",
    "# Assign to dataframe\n",
    "sub['Pred'] = predictions\n",
    "print(\"Saving to CSV...\")\n",
    "sub[['ID', 'Pred']].to_csv('submission.csv', index=False)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11484718,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
