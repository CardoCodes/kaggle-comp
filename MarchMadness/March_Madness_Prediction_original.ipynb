{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March Madness Prediction\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Goal\n",
    "Submissions are based on the Brier Score, the goal will be to minimize the brier score between the predicted probabilities and the actual game outcomes. The Brier score measures the accuracy of probablistic predition, in this case the mean square error. \n",
    "\n",
    "The brier score can be thought of as a cost function that measures the average squared difference between the predicted probabilities and the actual outcomes.\n",
    "\n",
    "$$\n",
    "Brier = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2\n",
    "$$\n",
    "\n",
    "where $p_i$ is the predicted probability of the event and $o_i$ is the actual outcome. The Brier score can span across all items in a set of N predictions.\n",
    "\n",
    "Therefore, minimizing the Brier score will result in a more accurate prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Numpy for numerical operations\n",
    "Pandas for data manipulation\n",
    "Matplotlib, Seaborn, Plotly for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sp\n",
    "import xgboost as xgb\n",
    "import sklearn as sk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We want to get a baseline model in which we can improve upon. In order to do this effectively, I will use a class structure to store all the data and functions that will be used along the process. This will make it easier to improve and maintain changes to the prediction process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarchMadnessPredictor:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.data = None\n",
    "        self.teams = None\n",
    "        self.seeds  = None\n",
    "        self.submission = None\n",
    "        self.all_compact_results = None\n",
    "        self.all_detailed_results = None\n",
    "        self.tourney_compact_results = None\n",
    "        self.tourney_detailed_results = None\n",
    "        self.model = None\n",
    "        self.calibration_model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Set up a data dictionary that will store the data for each file. e.g.\n",
    "        self.data = {\n",
    "            'teams': [DataFrame with teams data],\n",
    "            'games': [DataFrame with games data],\n",
    "            'players': [DataFrame with players data]\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        files = glob.glob(self.data_dir + '*.csv')\n",
    "        self.data = {file.split('\\\\')[-1].split('.')[0]: pd.read_csv(file, encoding='latin-1') for file in files}\n",
    "\n",
    "        self.submission = self.data['SampleSubmissionStage1']\n",
    "\n",
    "        teams = pd.concat([self.data['MTeams'], self.data['WTeams']])\n",
    "        teams_spelling = pd.concat([self.data['MTeamSpellings'], self.data['WTeamSpellings']])\n",
    "        teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "        teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "        self.teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "        #print(self.teams.head())\n",
    "\n",
    "        season_compact_results = pd.concat([self.data['MRegularSeasonCompactResults'], self.data['WRegularSeasonCompactResults']]).assign(ST='S')\n",
    "        season_detailed_results = pd.concat([self.data['MRegularSeasonDetailedResults'], self.data['WRegularSeasonDetailedResults']]).assign(ST='S')\n",
    "        tourney_compact_results = pd.concat([self.data['MNCAATourneyCompactResults'], self.data['WNCAATourneyCompactResults']]).assign(ST='T')\n",
    "        tourney_detailed_results = pd.concat([self.data['MNCAATourneyDetailedResults'], self.data['WNCAATourneyDetailedResults']]).assign(ST='T')\n",
    "\n",
    "        # Extract numeric seed value from seed string\n",
    "        seeds = pd.concat([self.data['MNCAATourneySeeds'], self.data['WNCAATourneySeeds']])\n",
    "        seeds['SeedValue'] = seeds['Seed'].str.extract('(\\d+)').astype(int)\n",
    "        self.seeds = seeds\n",
    "        print(self.seeds)\n",
    "\n",
    "        \"\"\"\n",
    "        Load the game data with additional derived features.\n",
    "        Combines regualr season and tournament results\n",
    "        \"\"\"\n",
    "\n",
    "        # Combine all game results\n",
    "        all_compact_results = pd.concat([season_compact_results, tourney_compact_results])\n",
    "        all_detailed_results = pd.concat([season_detailed_results, tourney_detailed_results])\n",
    "\n",
    "        # Add derived features to compact results\n",
    "        all_compact_results['ScoreDiff'] = all_compact_results['WScore'] - all_compact_results['LScore']\n",
    "        all_compact_results['HomeAdvantage'] = all_compact_results['WLoc'].map({'H': 1, 'N': 0, 'A': -1})\n",
    "        \n",
    "        # Add derived features to detaifled results\n",
    "        all_detailed_results['ScoreDiff'] = all_detailed_results['WScore'] - all_detailed_results['LScore']\n",
    "        all_detailed_results['HomeAdvantage'] = all_detailed_results['WLoc'].map({'H': 1, 'N': 0, 'A': -1})\n",
    "\n",
    "         # Calculate shooting percentages (handling division by zero)\n",
    "        all_detailed_results['WFGPct'] = np.where(all_detailed_results['WFGA'] > 0, \n",
    "                                                all_detailed_results['WFGM'] / all_detailed_results['WFGA'], 0)\n",
    "        all_detailed_results['WFG3Pct'] = np.where(all_detailed_results['WFGA3'] > 0, \n",
    "                                                all_detailed_results['WFGM3'] / all_detailed_results['WFGA3'], 0)\n",
    "        all_detailed_results['WFTPct'] = np.where(all_detailed_results['WFTA'] > 0, \n",
    "                                                all_detailed_results['WFTM'] / all_detailed_results['WFTA'], 0)\n",
    "        all_detailed_results['LFGPct'] = np.where(all_detailed_results['LFGA'] > 0, \n",
    "                                                all_detailed_results['LFGM'] / all_detailed_results['LFGA'], 0)\n",
    "        all_detailed_results['LFG3Pct'] = np.where(all_detailed_results['LFGA3'] > 0, \n",
    "                                                all_detailed_results['LFGM3'] / all_detailed_results['LFGA3'], 0)\n",
    "        all_detailed_results['LFTPct'] = np.where(all_detailed_results['LFTA'] > 0, \n",
    "                                                all_detailed_results['LFTM'] / all_detailed_results['LFTA'], 0)\n",
    "        \n",
    "        # Add statistical differences\n",
    "        all_detailed_results['ReboundDiff'] = (all_detailed_results['WOR'] + all_detailed_results['WDR']) - \\\n",
    "                                            (all_detailed_results['LOR'] + all_detailed_results['LDR'])\n",
    "        all_detailed_results['AssistDiff'] = all_detailed_results['WAst'] - all_detailed_results['LAst']\n",
    "        all_detailed_results['TurnoverDiff'] = all_detailed_results['WTO'] - all_detailed_results['LTO']\n",
    "        all_detailed_results['StealDiff'] = all_detailed_results['WStl'] - all_detailed_results['LStl']\n",
    "        all_detailed_results['BlockDiff'] = all_detailed_results['WBlk'] - all_detailed_results['LBlk']\n",
    "        all_detailed_results['FoulDiff'] = all_detailed_results['WPF'] - all_detailed_results['LPF']\n",
    "\n",
    "        # Add seed information to tournament games\n",
    "        tourney_compact = all_compact_results[all_compact_results['ST'] == 'T'].copy()\n",
    "        tourney_detailed = all_detailed_results[all_detailed_results['ST'] == 'T'].copy()\n",
    "\n",
    "        # Add winner seeds\n",
    "        tourney_compact = pd.merge(\n",
    "            tourney_compact,\n",
    "            seeds[['Season', 'TeamID', 'SeedValue']],\n",
    "            how='left',\n",
    "            left_on=['Season', 'WTeamID'],\n",
    "            right_on=['Season', 'TeamID']\n",
    "        )\n",
    "        tourney_compact.rename(columns={'SeedValue': 'WSeedValue'}, inplace=True)\n",
    "        tourney_compact.drop('TeamID', axis=1, inplace=True)\n",
    "        \n",
    "        tourney_detailed = pd.merge(\n",
    "            tourney_detailed,\n",
    "            seeds[['Season', 'TeamID', 'SeedValue']],\n",
    "            how='left',\n",
    "            left_on=['Season', 'WTeamID'],\n",
    "            right_on=['Season', 'TeamID']\n",
    "        )\n",
    "        tourney_detailed.rename(columns={'SeedValue': 'WSeedValue'}, inplace=True)\n",
    "        tourney_detailed.drop('TeamID', axis=1, inplace=True)\n",
    "\n",
    "        # Add loser seeds\n",
    "        tourney_compact = pd.merge(\n",
    "            tourney_compact,\n",
    "            seeds[['Season', 'TeamID', 'SeedValue']],\n",
    "            how='left',\n",
    "            left_on=['Season', 'LTeamID'],\n",
    "            right_on=['Season', 'TeamID']\n",
    "        )\n",
    "        tourney_compact.rename(columns={'SeedValue': 'LSeedValue'}, inplace=True)\n",
    "        tourney_compact.drop('TeamID', axis=1, inplace=True)\n",
    "        \n",
    "        tourney_detailed = pd.merge(\n",
    "            tourney_detailed,\n",
    "            seeds[['Season', 'TeamID', 'SeedValue']],\n",
    "            how='left',\n",
    "            left_on=['Season', 'LTeamID'],\n",
    "            right_on=['Season', 'TeamID']\n",
    "        )\n",
    "        tourney_detailed.rename(columns={'SeedValue': 'LSeedValue'}, inplace=True)\n",
    "        tourney_detailed.drop('TeamID', axis=1, inplace=True)\n",
    "\n",
    "         # Calculate seed difference (lower is better in seeding, so LSeed - WSeed is positive if favorite won)\n",
    "        tourney_compact['SeedDiff'] = tourney_compact['LSeedValue'] - tourney_compact['WSeedValue']\n",
    "        tourney_detailed['SeedDiff'] = tourney_detailed['LSeedValue'] - tourney_detailed['WSeedValue']\n",
    "\n",
    "        # Store all processed data\n",
    "        self.all_compact_results = all_compact_results\n",
    "        self.all_detailed_results = all_detailed_results\n",
    "        self.tourney_compact_results = tourney_compact\n",
    "        self.tourney_detailed_results = tourney_detailed\n",
    "\n",
    "        print(\"All Compact Resullts: \\n\", self.all_compact_results.head())\n",
    "        print(self.all_detailed_results.head())\n",
    "        print(self.tourney_compact_results.head())\n",
    "        print(self.tourney_detailed_results.head())\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Creates XGBoost models for prediction and calibration.\n",
    "        \"\"\"\n",
    "        # Main prediction model\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=500,         # Number of boosting rounds\n",
    "            learning_rate=0.05,       # Smaller learning rate for better generalization\n",
    "            max_depth=6,              # Control model complexity\n",
    "            min_child_weight=3,       # Helps prevent overfitting\n",
    "            subsample=0.8,            # Use 80% of data for each tree\n",
    "            colsample_bytree=0.8,     # Use 80% of features for each tree\n",
    "            objective='reg:squarederror',  # Optimizes for MSE which aligns with Brier score\n",
    "            random_state=42,\n",
    "            n_jobs=-1                 # Use all CPU cores\n",
    "        )\n",
    "        \n",
    "        # Calibration model to fine-tune probabilities\n",
    "        self.calibration_model = xgb.XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=4,\n",
    "            min_child_weight=2,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_dir = 'data/'\n",
    "    predictor = MarchMadnessPredictor(data_dir)\n",
    "    predictor.load_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
