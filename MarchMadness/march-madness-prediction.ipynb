{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91497,"databundleVersionId":11484718,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\nimport plotly.subplots as sp\nimport xgboost as xgb\nimport sklearn as sk\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import log_loss, mean_absolute_error, brier_score_loss\n\nplt.style.use(\"dark_background\")\npx.defaults.template = 'plotly_dark'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T03:40:34.483364Z","iopub.execute_input":"2025-03-23T03:40:34.483727Z","iopub.status.idle":"2025-03-23T03:40:34.490041Z","shell.execute_reply.started":"2025-03-23T03:40:34.483701Z","shell.execute_reply":"2025-03-23T03:40:34.488948Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"path = '/kaggle/input/march-machine-learning-mania-2025/**'\ndata = {p.split('/')[-1].split('.')[0] : pd.read_csv(p, encoding='latin-1') for p in glob.glob(path)}\n\nteams = pd.concat([data['MTeams'], data['WTeams']])\nteams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\nteams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\nteams_spelling.columns = ['TeamID', 'TeamNameCount']\nteams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n\nseason_compact_results = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']]).assign(ST='S')\nseason_detailed_results = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']]).assign(ST='S')\ntourney_compact_results = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']]).assign(ST='T')\ntourney_detailed_results = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']]).assign(ST='T')\n\nlots = pd.concat([data['MNCAATourneySlots'], data['WNCAATourneySlots']])\nseeds = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\nseeds['SeedValue'] = seeds['Seed'].str.extract(r'(\\d+)').astype(int)\nseeds_dict = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}\ngame_cities = pd.concat([data['MGameCities'], data['WGameCities']])\nseasons = pd.concat([data['MSeasons'], data['WSeasons']])\ncities = data['Cities']\nsub = data['SampleSubmissionStage1']\ndel data\n\nseeds = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T03:05:32.716608Z","iopub.execute_input":"2025-03-23T03:05:32.717275Z","iopub.status.idle":"2025-03-23T03:05:38.563274Z","shell.execute_reply.started":"2025-03-23T03:05:32.717234Z","shell.execute_reply":"2025-03-23T03:05:38.562315Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"all_detailed_results = pd.concat([season_detailed_results, tourney_detailed_results])\nall_detailed_results.reset_index(drop=True, inplace=True)\nall_detailed_results['WLoc'] = all_detailed_results['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n\nall_detailed_results['ID'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\nall_detailed_results['IDTeams'] = all_detailed_results.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\nall_detailed_results['Team1'] = all_detailed_results.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\nall_detailed_results['Team2'] = all_detailed_results.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\nall_detailed_results['IDTeam1'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\nall_detailed_results['IDTeam2'] = all_detailed_results.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n\nall_detailed_results['Team1Seed'] = all_detailed_results['IDTeam1'].map(seeds).fillna(0)\nall_detailed_results['Team2Seed'] = all_detailed_results['IDTeam2'].map(seeds).fillna(0)\n\nall_detailed_results['ScoreDiff'] = all_detailed_results['WScore'] - all_detailed_results['LScore']\nall_detailed_results['Pred'] = all_detailed_results.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\nall_detailed_results['ScoreDiffNorm'] = all_detailed_results.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\nall_detailed_results['SeedDiff'] = all_detailed_results['Team1Seed'] - all_detailed_results['Team2Seed'] \nall_detailed_results = all_detailed_results.fillna(-1)\n\n# Add derived features to detaifled results\nall_detailed_results['ScoreDiff'] = all_detailed_results['WScore'] - all_detailed_results['LScore']\nall_detailed_results['HomeAdvantage'] = all_detailed_results['WLoc'].map({'H': 1, 'N': 0, 'A': -1})\n\n    # Calculate shooting percentages (handling division by zero)\nall_detailed_results['WFGPct'] = np.where(all_detailed_results['WFGA'] > 0, \n                                        all_detailed_results['WFGM'] / all_detailed_results['WFGA'], 0)\nall_detailed_results['WFG3Pct'] = np.where(all_detailed_results['WFGA3'] > 0, \n                                        all_detailed_results['WFGM3'] / all_detailed_results['WFGA3'], 0)\nall_detailed_results['WFTPct'] = np.where(all_detailed_results['WFTA'] > 0, \n                                        all_detailed_results['WFTM'] / all_detailed_results['WFTA'], 0)\nall_detailed_results['LFGPct'] = np.where(all_detailed_results['LFGA'] > 0, \n                                        all_detailed_results['LFGM'] / all_detailed_results['LFGA'], 0)\nall_detailed_results['LFG3Pct'] = np.where(all_detailed_results['LFGA3'] > 0, \n                                        all_detailed_results['LFGM3'] / all_detailed_results['LFGA3'], 0)\nall_detailed_results['LFTPct'] = np.where(all_detailed_results['LFTA'] > 0, \n                                        all_detailed_results['LFTM'] / all_detailed_results['LFTA'], 0)\n\n# Add statistical differences\nall_detailed_results['ReboundDiff'] = (all_detailed_results['WOR'] + all_detailed_results['WDR']) - \\\n                                    (all_detailed_results['LOR'] + all_detailed_results['LDR'])\nall_detailed_results['AssistDiff'] = all_detailed_results['WAst'] - all_detailed_results['LAst']\nall_detailed_results['TurnoverDiff'] = all_detailed_results['WTO'] - all_detailed_results['LTO']\nall_detailed_results['StealDiff'] = all_detailed_results['WStl'] - all_detailed_results['LStl']\nall_detailed_results['BlockDiff'] = all_detailed_results['WBlk'] - all_detailed_results['LBlk']\nall_detailed_results['FoulDiff'] = all_detailed_results['WPF'] - all_detailed_results['LPF']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T03:05:38.565121Z","iopub.execute_input":"2025-03-23T03:05:38.565441Z","iopub.status.idle":"2025-03-23T03:05:56.243661Z","shell.execute_reply.started":"2025-03-23T03:05:38.565412Z","shell.execute_reply":"2025-03-23T03:05:56.242573Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl',\n 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl',\n 'LBlk', 'LPF']\nc_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\ngb = all_detailed_results.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\ngb.columns = [''.join(c) + '_c_score' for c in gb.columns]\n\nsub['WLoc'] = 3\nsub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\nsub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\nsub['Season'] = sub['Season'].astype(int)\nsub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\nsub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\nsub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\nsub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\nsub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\nsub['Team1Seed'] = sub['IDTeam1'].map(seeds).fillna(0)\nsub['Team2Seed'] = sub['IDTeam2'].map(seeds).fillna(0)\nsub['SeedDiff'] = sub['Team1Seed'] - sub['Team2Seed'] \nsub = sub.fillna(-1)\n\ngames = pd.merge(all_detailed_results, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\nsub = pd.merge(sub, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n\ncol = [c for c in games.columns if c not in ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc'] + c_score_col]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T03:05:56.244836Z","iopub.execute_input":"2025-03-23T03:05:56.245219Z","iopub.status.idle":"2025-03-23T03:06:16.162692Z","shell.execute_reply.started":"2025-03-23T03:05:56.245182Z","shell.execute_reply":"2025-03-23T03:06:16.161843Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='mean')  \nscaler = StandardScaler()\n\nX = games[col].fillna(-1)\nmissing_cols = set(col) - set(sub.columns)\nfor c in missing_cols:\n    sub[c] = 0\n\nX_imputed = imputer.fit_transform(X)\nX_scaled = scaler.fit_transform(X_imputed)\n\n# Main prediction model\nmodel = xgb.XGBRegressor(\n    n_estimators=5000,         # Number of boosting rounds\n    learning_rate=0.05,       # Smaller learning rate for better generalization\n    max_depth=6,              # Control model complexity\n    min_child_weight=3,       # Helps prevent overfitting\n    subsample=0.8,            # Use 80% of data for each tree\n    colsample_bytree=0.8,     # Use 80% of features for each tree\n    objective='binary:logistic',  # Binary classification with probability output\n    random_state=42,\n    n_jobs=-1                 # Use all CPU cores\n)\n\n# Train the main model\nprint(\"\\nTraining main model...\")\nmodel.fit(X_scaled, games['Pred'])\n\npred = model.predict(X_scaled).clip(0.001, 0.999)\n\n\nprint(f'Log Loss: {log_loss(games[\"Pred\"], pred)}')\nprint(f'Mean Absolute Error: {mean_absolute_error(games[\"Pred\"], pred)}')\nprint(f'Brier Score: {brier_score_loss(games[\"Pred\"], pred)}')\n\ncv_scores = cross_val_score(model, X_scaled, games['Pred'], cv=5, scoring='neg_mean_squared_error')\nprint(f'Cross-validated MSE: {-cv_scores.mean()}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T03:40:44.806961Z","iopub.execute_input":"2025-03-23T03:40:44.807278Z"}},"outputs":[{"name":"stdout","text":"\nTraining main model...\nLog Loss: 0.28307760044459745\nMean Absolute Error: 0.22842568247758735\nBrier Score: 0.0759942442218871\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"sub_X = sub[col].fillna(-1)\nsub_X_imputed = imputer.transform(sub_X)\nsub_X_scaled = scaler.transform(sub_X_imputed)\n\nsub['Pred'] = xgb.predict(sub_X_scaled).clip(0.001, 0.999)\nsub[['ID', 'Pred']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}